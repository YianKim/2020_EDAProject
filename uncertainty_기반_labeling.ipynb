{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2020_EDAProject/blob/main/uncertainty_%EA%B8%B0%EB%B0%98_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m"
      },
      "source": [
        "## 구글 드라이브\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTEuhg7fR9P",
        "outputId": "d7462533-ef83-4ff3-c153-c354e3bc778a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6b1qO5dSAyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962c7b39-4b42-4c5e-d26b-372fb082abc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(data, labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-e24WMOTQ4d"
      },
      "outputs": [],
      "source": [
        "train_data = data[range(10000)].reshape([10000,28,28,1])\n",
        "train_labels = labels[range(10000)].reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhhKskDITIEm"
      },
      "outputs": [],
      "source": [
        "unlab_data = data[range(10000,60000)].reshape([50000,28,28,1])\n",
        "unlab_labels = labels[range(10000,60000)].reshape([50000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5aNLvjxVUq0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape([10000,28,28,1])\n",
        "test_labels = test_labels.reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K2wXxMmUxRV"
      },
      "outputs": [],
      "source": [
        "train_labels2 = []\n",
        "unlab_labels2 = []\n",
        "test_labels2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c9LL8JVThd-"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[train_labels[i][0]] = 1\n",
        "  train_labels2.append(white)\n",
        "\n",
        "for i in range(50000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[unlab_labels[i][0]] = 1\n",
        "  unlab_labels2.append(white)\n",
        "\n",
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[test_labels[i][0]] = 1\n",
        "  test_labels2.append(white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iULFrchUU5nt"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels2)\n",
        "unlab_labels = np.array(unlab_labels2)\n",
        "test_labels = np.array(test_labels2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa7KYMfrkKU5"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn3v_W8wJQ68"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5scE9yKkIZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd502ca2-707a-4f7b-94d6-04e54e8f53b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 2.7861 - accuracy: 0.6353 - val_loss: 0.8022 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.6622 - accuracy: 0.7697 - val_loss: 0.6885 - val_accuracy: 0.7657 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5660 - accuracy: 0.7983 - val_loss: 0.6609 - val_accuracy: 0.7703 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.5037 - accuracy: 0.8180 - val_loss: 0.6342 - val_accuracy: 0.7733 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.4535 - accuracy: 0.8319 - val_loss: 0.6077 - val_accuracy: 0.7847 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.4147 - accuracy: 0.8441 - val_loss: 0.6093 - val_accuracy: 0.7960 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3875 - accuracy: 0.8536 - val_loss: 0.5940 - val_accuracy: 0.8060 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3651 - accuracy: 0.8620 - val_loss: 0.6273 - val_accuracy: 0.7880 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.3484 - accuracy: 0.8674 - val_loss: 0.5626 - val_accuracy: 0.8103 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3273 - accuracy: 0.8746 - val_loss: 0.5927 - val_accuracy: 0.8113 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3090 - accuracy: 0.8860 - val_loss: 0.5859 - val_accuracy: 0.8240 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.3131 - accuracy: 0.8794 - val_loss: 0.5742 - val_accuracy: 0.8090 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.2778 - accuracy: 0.8929 - val_loss: 0.5907 - val_accuracy: 0.8323 - lr: 9.0000e-04\n",
            "Epoch 14/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2729 - accuracy: 0.8961 - val_loss: 0.5712 - val_accuracy: 0.8227 - lr: 9.0000e-04\n",
            "Epoch 15/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2541 - accuracy: 0.9053 - val_loss: 0.5767 - val_accuracy: 0.8237 - lr: 9.0000e-04\n",
            "Epoch 16/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2243 - accuracy: 0.9087 - val_loss: 0.5890 - val_accuracy: 0.8267 - lr: 8.1000e-04\n",
            "Epoch 17/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2309 - accuracy: 0.9153 - val_loss: 0.5225 - val_accuracy: 0.8367 - lr: 8.1000e-04\n",
            "Epoch 18/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2139 - accuracy: 0.9154 - val_loss: 0.6367 - val_accuracy: 0.8207 - lr: 8.1000e-04\n",
            "Epoch 19/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.2108 - accuracy: 0.9201 - val_loss: 0.6230 - val_accuracy: 0.8290 - lr: 8.1000e-04\n",
            "Epoch 20/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.2063 - accuracy: 0.9216 - val_loss: 0.5511 - val_accuracy: 0.8253 - lr: 8.1000e-04\n",
            "Epoch 21/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1996 - accuracy: 0.9220 - val_loss: 0.6019 - val_accuracy: 0.8410 - lr: 7.2900e-04\n",
            "Epoch 22/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.1856 - accuracy: 0.9277 - val_loss: 0.6083 - val_accuracy: 0.8363 - lr: 7.2900e-04\n",
            "Epoch 23/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.1837 - accuracy: 0.9327 - val_loss: 0.5663 - val_accuracy: 0.8403 - lr: 7.2900e-04\n",
            "Epoch 24/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1730 - accuracy: 0.9323 - val_loss: 0.6454 - val_accuracy: 0.8340 - lr: 6.5610e-04\n",
            "Epoch 25/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1771 - accuracy: 0.9337 - val_loss: 0.5955 - val_accuracy: 0.8400 - lr: 6.5610e-04\n",
            "Epoch 26/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9359 - val_loss: 0.6574 - val_accuracy: 0.8490 - lr: 6.5610e-04\n",
            "Epoch 27/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.9437 - val_loss: 0.5983 - val_accuracy: 0.8420 - lr: 5.9049e-04\n",
            "Epoch 28/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1570 - accuracy: 0.9377 - val_loss: 0.5854 - val_accuracy: 0.8427 - lr: 5.9049e-04\n",
            "Epoch 29/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1430 - accuracy: 0.9453 - val_loss: 0.6304 - val_accuracy: 0.8423 - lr: 5.9049e-04\n",
            "Epoch 30/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9417 - val_loss: 0.6161 - val_accuracy: 0.8453 - lr: 5.3144e-04\n",
            "Epoch 31/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1304 - accuracy: 0.9476 - val_loss: 0.6837 - val_accuracy: 0.8493 - lr: 5.3144e-04\n",
            "Epoch 32/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1324 - accuracy: 0.9506 - val_loss: 0.6736 - val_accuracy: 0.8417 - lr: 5.3144e-04\n",
            "Epoch 33/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.1230 - accuracy: 0.9506 - val_loss: 0.6286 - val_accuracy: 0.8537 - lr: 4.7830e-04\n",
            "Epoch 34/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.9549 - val_loss: 0.6975 - val_accuracy: 0.8487 - lr: 4.7830e-04\n",
            "Epoch 35/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.1096 - accuracy: 0.9594 - val_loss: 0.6967 - val_accuracy: 0.8410 - lr: 4.7830e-04\n",
            "Epoch 36/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.1157 - accuracy: 0.9544 - val_loss: 0.6762 - val_accuracy: 0.8450 - lr: 4.3047e-04\n",
            "Epoch 37/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9571 - val_loss: 0.6750 - val_accuracy: 0.8483 - lr: 4.3047e-04\n",
            "Epoch 38/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1140 - accuracy: 0.9581 - val_loss: 0.6487 - val_accuracy: 0.8533 - lr: 4.3047e-04\n",
            "Epoch 39/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1128 - accuracy: 0.9583 - val_loss: 0.7209 - val_accuracy: 0.8430 - lr: 3.8742e-04\n",
            "Epoch 40/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0980 - accuracy: 0.9617 - val_loss: 0.6998 - val_accuracy: 0.8470 - lr: 3.8742e-04\n",
            "Epoch 41/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.1133 - accuracy: 0.9594 - val_loss: 0.6909 - val_accuracy: 0.8463 - lr: 3.8742e-04\n",
            "Epoch 42/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0996 - accuracy: 0.9633 - val_loss: 0.6437 - val_accuracy: 0.8487 - lr: 3.4868e-04\n",
            "Epoch 43/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0894 - accuracy: 0.9647 - val_loss: 0.7056 - val_accuracy: 0.8480 - lr: 3.4868e-04\n",
            "Epoch 44/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0814 - accuracy: 0.9701 - val_loss: 0.7521 - val_accuracy: 0.8453 - lr: 3.4868e-04\n",
            "Epoch 45/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0893 - accuracy: 0.9651 - val_loss: 0.7849 - val_accuracy: 0.8517 - lr: 3.1381e-04\n",
            "Epoch 46/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0838 - accuracy: 0.9679 - val_loss: 0.7041 - val_accuracy: 0.8613 - lr: 3.1381e-04\n",
            "Epoch 47/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0802 - accuracy: 0.9704 - val_loss: 0.7954 - val_accuracy: 0.8493 - lr: 3.1381e-04\n",
            "Epoch 48/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0749 - accuracy: 0.9723 - val_loss: 0.7951 - val_accuracy: 0.8473 - lr: 2.8243e-04\n",
            "Epoch 49/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9710 - val_loss: 0.7604 - val_accuracy: 0.8540 - lr: 2.8243e-04\n",
            "Epoch 50/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9710 - val_loss: 0.8436 - val_accuracy: 0.8450 - lr: 2.8243e-04\n",
            "Epoch 51/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0710 - accuracy: 0.9734 - val_loss: 0.7736 - val_accuracy: 0.8533 - lr: 2.5419e-04\n",
            "Epoch 52/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9733 - val_loss: 0.7376 - val_accuracy: 0.8623 - lr: 2.5419e-04\n",
            "Epoch 53/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0749 - accuracy: 0.9721 - val_loss: 0.7772 - val_accuracy: 0.8520 - lr: 2.5419e-04\n",
            "Epoch 54/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0674 - accuracy: 0.9726 - val_loss: 0.7939 - val_accuracy: 0.8547 - lr: 2.2877e-04\n",
            "Epoch 55/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0652 - accuracy: 0.9763 - val_loss: 0.7681 - val_accuracy: 0.8520 - lr: 2.2877e-04\n",
            "Epoch 56/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0588 - accuracy: 0.9763 - val_loss: 0.8275 - val_accuracy: 0.8483 - lr: 2.2877e-04\n",
            "Epoch 57/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0555 - accuracy: 0.9789 - val_loss: 0.7841 - val_accuracy: 0.8540 - lr: 2.0589e-04\n",
            "Epoch 58/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0637 - accuracy: 0.9756 - val_loss: 0.7394 - val_accuracy: 0.8577 - lr: 2.0589e-04\n",
            "Epoch 59/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0688 - accuracy: 0.9726 - val_loss: 0.7667 - val_accuracy: 0.8583 - lr: 2.0589e-04\n",
            "Epoch 60/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0619 - accuracy: 0.9764 - val_loss: 0.7992 - val_accuracy: 0.8530 - lr: 1.8530e-04\n",
            "Epoch 61/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0554 - accuracy: 0.9791 - val_loss: 0.8148 - val_accuracy: 0.8540 - lr: 1.8530e-04\n",
            "Epoch 62/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0569 - accuracy: 0.9784 - val_loss: 0.8313 - val_accuracy: 0.8507 - lr: 1.8530e-04\n",
            "Epoch 63/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0588 - accuracy: 0.9761 - val_loss: 0.8346 - val_accuracy: 0.8527 - lr: 1.6677e-04\n",
            "Epoch 64/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9790 - val_loss: 0.8305 - val_accuracy: 0.8557 - lr: 1.6677e-04\n",
            "Epoch 65/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0587 - accuracy: 0.9784 - val_loss: 0.8132 - val_accuracy: 0.8493 - lr: 1.6677e-04\n",
            "Epoch 66/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0503 - accuracy: 0.9817 - val_loss: 0.7835 - val_accuracy: 0.8600 - lr: 1.5009e-04\n",
            "Epoch 67/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0503 - accuracy: 0.9811 - val_loss: 0.8349 - val_accuracy: 0.8570 - lr: 1.5009e-04\n",
            "Epoch 68/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0479 - accuracy: 0.9830 - val_loss: 0.8480 - val_accuracy: 0.8530 - lr: 1.5009e-04\n",
            "Epoch 69/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0548 - accuracy: 0.9781 - val_loss: 0.7804 - val_accuracy: 0.8563 - lr: 1.3509e-04\n",
            "Epoch 70/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9814 - val_loss: 0.8095 - val_accuracy: 0.8593 - lr: 1.3509e-04\n",
            "Epoch 71/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0464 - accuracy: 0.9817 - val_loss: 0.8521 - val_accuracy: 0.8570 - lr: 1.3509e-04\n",
            "Epoch 72/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0464 - accuracy: 0.9819 - val_loss: 0.8642 - val_accuracy: 0.8537 - lr: 1.2158e-04\n",
            "Epoch 73/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 0.8261 - val_accuracy: 0.8647 - lr: 1.2158e-04\n",
            "Epoch 74/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 0.8611 - val_accuracy: 0.8500 - lr: 1.2158e-04\n",
            "Epoch 75/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.8675 - val_accuracy: 0.8560 - lr: 1.0942e-04\n",
            "Epoch 76/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0467 - accuracy: 0.9813 - val_loss: 0.7556 - val_accuracy: 0.8637 - lr: 1.0942e-04\n",
            "Epoch 77/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0461 - accuracy: 0.9824 - val_loss: 0.8812 - val_accuracy: 0.8587 - lr: 1.0942e-04\n",
            "Epoch 78/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 0.8422 - val_accuracy: 0.8577 - lr: 9.8477e-05\n",
            "Epoch 79/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 0.8772 - val_accuracy: 0.8567 - lr: 9.8477e-05\n",
            "Epoch 80/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0464 - accuracy: 0.9819 - val_loss: 0.8125 - val_accuracy: 0.8683 - lr: 9.8477e-05\n",
            "Epoch 81/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9843 - val_loss: 0.7982 - val_accuracy: 0.8613 - lr: 8.8629e-05\n",
            "Epoch 82/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9843 - val_loss: 0.8793 - val_accuracy: 0.8537 - lr: 8.8629e-05\n",
            "Epoch 83/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 0.8348 - val_accuracy: 0.8583 - lr: 8.8629e-05\n",
            "Epoch 84/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0415 - accuracy: 0.9854 - val_loss: 0.8629 - val_accuracy: 0.8613 - lr: 7.9766e-05\n",
            "Epoch 85/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.7607 - val_accuracy: 0.8537 - lr: 7.9766e-05\n",
            "Epoch 86/2000\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 0.8730 - val_accuracy: 0.8593 - lr: 7.9766e-05\n",
            "Epoch 87/2000\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.8336 - val_accuracy: 0.8617 - lr: 7.1790e-05\n",
            "Epoch 88/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0379 - accuracy: 0.9850 - val_loss: 0.8536 - val_accuracy: 0.8673 - lr: 7.1790e-05\n",
            "Epoch 89/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9847 - val_loss: 0.7964 - val_accuracy: 0.8667 - lr: 7.1790e-05\n",
            "Epoch 90/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0386 - accuracy: 0.9860 - val_loss: 0.8580 - val_accuracy: 0.8650 - lr: 6.4611e-05\n",
            "Epoch 91/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.8496 - val_accuracy: 0.8610 - lr: 6.4611e-05\n",
            "Epoch 92/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.9588 - val_accuracy: 0.8627 - lr: 6.4611e-05\n",
            "Epoch 93/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9850 - val_loss: 0.8527 - val_accuracy: 0.8667 - lr: 5.8150e-05\n",
            "Epoch 94/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9853 - val_loss: 0.8806 - val_accuracy: 0.8647 - lr: 5.8150e-05\n",
            "Epoch 95/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9863 - val_loss: 0.9311 - val_accuracy: 0.8583 - lr: 5.8150e-05\n",
            "Epoch 96/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0376 - accuracy: 0.9851 - val_loss: 0.8524 - val_accuracy: 0.8587 - lr: 5.2335e-05\n",
            "Epoch 97/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9851 - val_loss: 0.9141 - val_accuracy: 0.8583 - lr: 5.2335e-05\n",
            "Epoch 98/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9871 - val_loss: 0.8291 - val_accuracy: 0.8630 - lr: 5.2335e-05\n",
            "Epoch 99/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9844 - val_loss: 0.8712 - val_accuracy: 0.8617 - lr: 4.7101e-05\n",
            "Epoch 100/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9854 - val_loss: 0.8790 - val_accuracy: 0.8673 - lr: 4.7101e-05\n",
            "Epoch 101/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9876 - val_loss: 0.8558 - val_accuracy: 0.8627 - lr: 4.7101e-05\n",
            "Epoch 102/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9873 - val_loss: 0.8305 - val_accuracy: 0.8610 - lr: 4.2391e-05\n",
            "Epoch 103/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.8511 - val_accuracy: 0.8587 - lr: 4.2391e-05\n",
            "Epoch 104/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9881 - val_loss: 0.8320 - val_accuracy: 0.8617 - lr: 4.2391e-05\n",
            "Epoch 105/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9866 - val_loss: 0.9001 - val_accuracy: 0.8563 - lr: 3.8152e-05\n",
            "Epoch 106/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9894 - val_loss: 0.8651 - val_accuracy: 0.8577 - lr: 3.8152e-05\n",
            "Epoch 107/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.8657 - val_accuracy: 0.8670 - lr: 3.8152e-05\n",
            "Epoch 108/2000\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0333 - accuracy: 0.9869 - val_loss: 0.8706 - val_accuracy: 0.8670 - lr: 3.4337e-05\n",
            "Epoch 109/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 0.9148 - val_accuracy: 0.8603 - lr: 3.4337e-05\n",
            "Epoch 110/2000\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.8359 - val_accuracy: 0.8567 - lr: 3.4337e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f703c9d10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVOc3hYIkXrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5D8i_BCkdjS"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzhQw9NOWjl3",
        "outputId": "e4a56e3d-8c45-42f6-b518-4ad2042a468e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8829"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Jb5VX9ZC3y",
        "outputId": "40b6a8ac-29cd-439e-8340-cd4badf08a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [01:28<00:00,  2.95s/it]\n",
            "100%|██████████| 50000/50000 [00:07<00:00, 6457.61it/s]\n"
          ]
        }
      ],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIFHtGqAF9B"
      },
      "source": [
        "class마다 균등하게 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGGKCzvAiZb",
        "outputId": "8cb498c2-8dfa-45d7-b315-c0276b005a5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 5058,\n",
              "         1: 4973,\n",
              "         2: 4984,\n",
              "         3: 4981,\n",
              "         4: 5026,\n",
              "         5: 5011,\n",
              "         6: 4979,\n",
              "         7: 4978,\n",
              "         8: 5010,\n",
              "         9: 5000})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불확정성 컷 1"
      ],
      "metadata": {
        "id": "BUrklzVkE66r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAwvSCVBLA4",
        "outputId": "2fc40e80-4c31-46d8-a5ab-273d54f3d629"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [01:24<00:00, 590.23it/s]\n",
            "100%|██████████| 50000/50000 [01:29<00:00, 561.58it/s]\n",
            "100%|██████████| 50000/50000 [01:25<00:00, 585.09it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 589.09it/s]\n",
            "100%|██████████| 50000/50000 [01:25<00:00, 585.43it/s]\n",
            "100%|██████████| 50000/50000 [01:26<00:00, 578.97it/s]\n",
            "100%|██████████| 50000/50000 [01:26<00:00, 578.81it/s]\n",
            "100%|██████████| 50000/50000 [01:27<00:00, 573.93it/s]\n",
            "100%|██████████| 50000/50000 [01:27<00:00, 573.30it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 589.32it/s]\n"
          ]
        }
      ],
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB = []\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB.append(np.percentile(classvars, 50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BUHoKvtkJ37"
      },
      "outputs": [],
      "source": [
        "lowvars = []\n",
        "ind = 0 \n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    lowvars.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WhEDezq362P"
      },
      "outputs": [],
      "source": [
        "highvars = []\n",
        "for i in range(unlab_data.shape[0]):\n",
        "  if i not in lowvars:\n",
        "    highvars.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uSdhE1VmF5a",
        "outputId": "c427ea32-0e5c-4928-be41-4cdef55df959"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.89192"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtEPD5p5kM-z",
        "outputId": "e6c93b65-dfe5-49f6-ab77-79f7d0814c6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9728878433874247"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 저분산의 data들만 모아서 모델로 label 부여 후 정확도 측정 : 95% 이상\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2ab4GUWwe30"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xahhoBY8mKc"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gQWZXNojDvb"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tdOxYBQjFGT"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t9J8vlJ5TDO"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[randomindx2]\n",
        "unlab_labels_2 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Jq-n0L8diD",
        "outputId": "9dfcefff-d842-4581-de6b-579daea38e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 3600,\n",
              "         1: 3599,\n",
              "         2: 3613,\n",
              "         3: 3638,\n",
              "         4: 3469,\n",
              "         5: 3491,\n",
              "         6: 3151,\n",
              "         7: 3507,\n",
              "         8: 3505,\n",
              "         9: 3508})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CLpAKvu8kD6",
        "outputId": "00fce93a-128c-471e-d460-410106f853da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 3409,\n",
              "         1: 3473,\n",
              "         2: 3582,\n",
              "         3: 3546,\n",
              "         4: 3512,\n",
              "         5: 3488,\n",
              "         6: 3448,\n",
              "         7: 3581,\n",
              "         8: 3447,\n",
              "         9: 3514})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5t5J130x7pe",
        "outputId": "6c32f60a-2251-4d7c-e35a-b8e445dbb790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 2529,\n",
              "         1: 2407,\n",
              "         2: 2492,\n",
              "         3: 2490,\n",
              "         4: 2513,\n",
              "         5: 2505,\n",
              "         6: 2489,\n",
              "         7: 2489,\n",
              "         8: 2505,\n",
              "         9: 2500})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBMxw6eEx92l",
        "outputId": "57ac6607-fa7f-4bc9-8e0b-f4e876ab52d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 2565,\n",
              "         1: 2496,\n",
              "         2: 2452,\n",
              "         3: 2497,\n",
              "         4: 2506,\n",
              "         5: 2458,\n",
              "         6: 2504,\n",
              "         7: 2474,\n",
              "         8: 2554,\n",
              "         9: 2494})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불확정성 컷 2"
      ],
      "metadata": {
        "id": "qXY6ufSkE_rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB25 = []\n",
        "UB50 = []\n",
        "UB75 = []\n",
        "\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB25.append(np.percentile(classvars, 25))\n",
        "  UB50.append(np.percentile(classvars, 50))\n",
        "  UB75.append(np.percentile(classvars, 75))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEPgF4EWEdGx",
        "outputId": "758dc5b8-69fe-477b-ea13-e98fb3bae819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [01:24<00:00, 594.45it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 591.43it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 588.57it/s]\n",
            "100%|██████████| 50000/50000 [01:23<00:00, 600.10it/s]\n",
            "100%|██████████| 50000/50000 [01:22<00:00, 606.01it/s]\n",
            "100%|██████████| 50000/50000 [01:20<00:00, 617.92it/s]\n",
            "100%|██████████| 50000/50000 [01:21<00:00, 616.94it/s]\n",
            "100%|██████████| 50000/50000 [01:20<00:00, 617.50it/s]\n",
            "100%|██████████| 50000/50000 [01:20<00:00, 617.55it/s]\n",
            "100%|██████████| 50000/50000 [01:20<00:00, 620.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UB25 < UB50 < UB75"
      ],
      "metadata": {
        "id": "F2m-BBSNFRO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOq_mV-uFGKX"
      },
      "outputs": [],
      "source": [
        "vars25 = []\n",
        "vars50 = []\n",
        "vars75 = []\n",
        "vars100 = []\n",
        "\n",
        "ind = 0 \n",
        "\n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB25[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars25.append(ind)\n",
        "  elif i <= UB50[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars50.append(ind)\n",
        "  elif i <= UB75[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars75.append(ind)\n",
        "  else:\n",
        "    vars100.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k1 = random.sample(range(len(vars25)), len(vars25))\n",
        "k2 = random.sample(range(len(vars50)), len(vars50))\n",
        "k3 = random.sample(range(len(vars75)), len(vars75))\n",
        "k4 = random.sample(range(len(vars100)), len(vars100))\n",
        "\n",
        "lowvars = k1[0:np.int(len(k1)/2)] + k2[0:np.int(len(k2)/2)] + k3[0:np.int(len(k3)/2)] + k4[0:np.int(len(k4)/2)]\n",
        "highvars = k1[np.int(len(k1)/2):len(k1)] + k2[np.int(len(k2)/2):len(k2)] + k3[np.int(len(k3)/2):len(k3)] + k4[np.int(len(k4)/2):len(k4)]"
      ],
      "metadata": {
        "id": "5kx2MFUxKh6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175d1e1f-1c67-4bef-ab39-5d92e1ec1a17",
        "id": "cHARP-fyFGKX"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89508"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb723c49-6b09-4067-9965-4451079a43c3",
        "id": "DU2TXlLaFGKY"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8944757790311613"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# 층화추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ka9xFulFGKY"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLqnYj4ZFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvb7FhRaFGKZ"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsSWcAFHFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F39Oc7V8FGKZ"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[randomindx2]\n",
        "unlab_labels_2 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d86e60-8c34-41b0-e54e-8505825b4e77",
        "id": "MMw4VfmaFGKZ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3346,\n",
              "         1: 3485,\n",
              "         2: 3492,\n",
              "         3: 3595,\n",
              "         4: 3516,\n",
              "         5: 3507,\n",
              "         6: 3528,\n",
              "         7: 3500,\n",
              "         8: 3510,\n",
              "         9: 3520})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49bfe70-ff13-4e79-973a-43ed011a79a0",
        "id": "o5ZZKXxBFGKZ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3375,\n",
              "         1: 3463,\n",
              "         2: 3521,\n",
              "         3: 3513,\n",
              "         4: 3574,\n",
              "         5: 3426,\n",
              "         6: 3541,\n",
              "         7: 3583,\n",
              "         8: 3469,\n",
              "         9: 3535})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2fd7aa4-8f74-4cff-97e3-7dc681afb9d9",
        "id": "Y05Wb3HZFGKa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2542,\n",
              "         1: 2491,\n",
              "         2: 2451,\n",
              "         3: 2505,\n",
              "         4: 2433,\n",
              "         5: 2509,\n",
              "         6: 2676,\n",
              "         7: 2556,\n",
              "         8: 2313,\n",
              "         9: 2525})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc348e84-ca69-4082-91e1-166be578140e",
        "id": "qHWvlgD4FGKa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2532,\n",
              "         1: 2500,\n",
              "         2: 2525,\n",
              "         3: 2539,\n",
              "         4: 2434,\n",
              "         5: 2522,\n",
              "         6: 2487,\n",
              "         7: 2463,\n",
              "         8: 2514,\n",
              "         9: 2484})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Pd9SYK5tv_"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6WgyM3Y5twA",
        "outputId": "7a0ad540-3b41-4fb4-fb0d-2fcc236bd2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 5s 12ms/step - loss: 1.1925 - accuracy: 0.6126 - val_loss: 0.6793 - val_accuracy: 0.7716 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.6240 - accuracy: 0.7889 - val_loss: 0.5945 - val_accuracy: 0.7977 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.5377 - accuracy: 0.8277 - val_loss: 0.5035 - val_accuracy: 0.8390 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4882 - accuracy: 0.8422 - val_loss: 0.4723 - val_accuracy: 0.8481 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4643 - accuracy: 0.8558 - val_loss: 0.4740 - val_accuracy: 0.8491 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4406 - accuracy: 0.8667 - val_loss: 0.4313 - val_accuracy: 0.8682 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4175 - accuracy: 0.8724 - val_loss: 0.4325 - val_accuracy: 0.8622 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4081 - accuracy: 0.8785 - val_loss: 0.4095 - val_accuracy: 0.8810 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4015 - accuracy: 0.8838 - val_loss: 0.4178 - val_accuracy: 0.8727 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3959 - accuracy: 0.8844 - val_loss: 0.3993 - val_accuracy: 0.8822 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3904 - accuracy: 0.8880 - val_loss: 0.3913 - val_accuracy: 0.8867 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3800 - accuracy: 0.8922 - val_loss: 0.3888 - val_accuracy: 0.8875 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3719 - accuracy: 0.8939 - val_loss: 0.3905 - val_accuracy: 0.8847 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3694 - accuracy: 0.8978 - val_loss: 0.3836 - val_accuracy: 0.8900 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3670 - accuracy: 0.8982 - val_loss: 0.3742 - val_accuracy: 0.8931 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3581 - accuracy: 0.9037 - val_loss: 0.3802 - val_accuracy: 0.8916 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3573 - accuracy: 0.9050 - val_loss: 0.3800 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3543 - accuracy: 0.9026 - val_loss: 0.3750 - val_accuracy: 0.8933 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3461 - accuracy: 0.9072 - val_loss: 0.3794 - val_accuracy: 0.8944 - lr: 9.0000e-04\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3407 - accuracy: 0.9085 - val_loss: 0.3697 - val_accuracy: 0.8981 - lr: 9.0000e-04\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3374 - accuracy: 0.9105 - val_loss: 0.3726 - val_accuracy: 0.8960 - lr: 9.0000e-04\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3377 - accuracy: 0.9097 - val_loss: 0.3647 - val_accuracy: 0.8974 - lr: 9.0000e-04\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3332 - accuracy: 0.9129 - val_loss: 0.3722 - val_accuracy: 0.8961 - lr: 9.0000e-04\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3332 - accuracy: 0.9137 - val_loss: 0.3634 - val_accuracy: 0.9028 - lr: 9.0000e-04\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3342 - accuracy: 0.9104 - val_loss: 0.3633 - val_accuracy: 0.8990 - lr: 9.0000e-04\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3289 - accuracy: 0.9144 - val_loss: 0.3617 - val_accuracy: 0.8990 - lr: 9.0000e-04\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3288 - accuracy: 0.9152 - val_loss: 0.3555 - val_accuracy: 0.9000 - lr: 9.0000e-04\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3239 - accuracy: 0.9169 - val_loss: 0.3606 - val_accuracy: 0.9011 - lr: 9.0000e-04\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3221 - accuracy: 0.9182 - val_loss: 0.3559 - val_accuracy: 0.9005 - lr: 9.0000e-04\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3234 - accuracy: 0.9160 - val_loss: 0.3585 - val_accuracy: 0.9009 - lr: 9.0000e-04\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3160 - accuracy: 0.9203 - val_loss: 0.3488 - val_accuracy: 0.9082 - lr: 8.1000e-04\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3155 - accuracy: 0.9203 - val_loss: 0.3507 - val_accuracy: 0.9043 - lr: 8.1000e-04\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3141 - accuracy: 0.9213 - val_loss: 0.3497 - val_accuracy: 0.9068 - lr: 8.1000e-04\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3101 - accuracy: 0.9248 - val_loss: 0.3518 - val_accuracy: 0.9084 - lr: 8.1000e-04\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3044 - accuracy: 0.9241 - val_loss: 0.3422 - val_accuracy: 0.9117 - lr: 7.2900e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3008 - accuracy: 0.9284 - val_loss: 0.3459 - val_accuracy: 0.9093 - lr: 7.2900e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3006 - accuracy: 0.9259 - val_loss: 0.3441 - val_accuracy: 0.9117 - lr: 7.2900e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3018 - accuracy: 0.9252 - val_loss: 0.3438 - val_accuracy: 0.9095 - lr: 7.2900e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2947 - accuracy: 0.9290 - val_loss: 0.3377 - val_accuracy: 0.9141 - lr: 6.5610e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2920 - accuracy: 0.9304 - val_loss: 0.3394 - val_accuracy: 0.9131 - lr: 6.5610e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2903 - accuracy: 0.9347 - val_loss: 0.3384 - val_accuracy: 0.9130 - lr: 6.5610e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2867 - accuracy: 0.9327 - val_loss: 0.3410 - val_accuracy: 0.9113 - lr: 6.5610e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2875 - accuracy: 0.9322 - val_loss: 0.3450 - val_accuracy: 0.9116 - lr: 5.9049e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2854 - accuracy: 0.9344 - val_loss: 0.3382 - val_accuracy: 0.9171 - lr: 5.9049e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2841 - accuracy: 0.9342 - val_loss: 0.3345 - val_accuracy: 0.9128 - lr: 5.9049e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2827 - accuracy: 0.9372 - val_loss: 0.3388 - val_accuracy: 0.9139 - lr: 5.9049e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2827 - accuracy: 0.9376 - val_loss: 0.3314 - val_accuracy: 0.9164 - lr: 5.9049e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2806 - accuracy: 0.9373 - val_loss: 0.3327 - val_accuracy: 0.9148 - lr: 5.9049e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2775 - accuracy: 0.9399 - val_loss: 0.3385 - val_accuracy: 0.9131 - lr: 5.9049e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2785 - accuracy: 0.9392 - val_loss: 0.3312 - val_accuracy: 0.9151 - lr: 5.9049e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2757 - accuracy: 0.9391 - val_loss: 0.3278 - val_accuracy: 0.9187 - lr: 5.9049e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2772 - accuracy: 0.9393 - val_loss: 0.3377 - val_accuracy: 0.9150 - lr: 5.9049e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2762 - accuracy: 0.9394 - val_loss: 0.3349 - val_accuracy: 0.9168 - lr: 5.9049e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2735 - accuracy: 0.9397 - val_loss: 0.3320 - val_accuracy: 0.9180 - lr: 5.9049e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2710 - accuracy: 0.9431 - val_loss: 0.3369 - val_accuracy: 0.9148 - lr: 5.3144e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2709 - accuracy: 0.9418 - val_loss: 0.3315 - val_accuracy: 0.9162 - lr: 5.3144e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2706 - accuracy: 0.9401 - val_loss: 0.3297 - val_accuracy: 0.9175 - lr: 5.3144e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2674 - accuracy: 0.9442 - val_loss: 0.3282 - val_accuracy: 0.9158 - lr: 4.7830e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2657 - accuracy: 0.9444 - val_loss: 0.3340 - val_accuracy: 0.9152 - lr: 4.7830e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2638 - accuracy: 0.9445 - val_loss: 0.3243 - val_accuracy: 0.9182 - lr: 4.7830e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2627 - accuracy: 0.9455 - val_loss: 0.3277 - val_accuracy: 0.9223 - lr: 4.7830e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2612 - accuracy: 0.9464 - val_loss: 0.3260 - val_accuracy: 0.9202 - lr: 4.7830e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2621 - accuracy: 0.9466 - val_loss: 0.3333 - val_accuracy: 0.9147 - lr: 4.7830e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2604 - accuracy: 0.9461 - val_loss: 0.3265 - val_accuracy: 0.9216 - lr: 4.3047e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2590 - accuracy: 0.9482 - val_loss: 0.3276 - val_accuracy: 0.9216 - lr: 4.3047e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2573 - accuracy: 0.9488 - val_loss: 0.3262 - val_accuracy: 0.9228 - lr: 4.3047e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2554 - accuracy: 0.9506 - val_loss: 0.3225 - val_accuracy: 0.9231 - lr: 3.8742e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2545 - accuracy: 0.9494 - val_loss: 0.3246 - val_accuracy: 0.9211 - lr: 3.8742e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2538 - accuracy: 0.9494 - val_loss: 0.3227 - val_accuracy: 0.9207 - lr: 3.8742e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2521 - accuracy: 0.9514 - val_loss: 0.3208 - val_accuracy: 0.9198 - lr: 3.8742e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2520 - accuracy: 0.9520 - val_loss: 0.3237 - val_accuracy: 0.9208 - lr: 3.8742e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2503 - accuracy: 0.9533 - val_loss: 0.3278 - val_accuracy: 0.9208 - lr: 3.8742e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2498 - accuracy: 0.9502 - val_loss: 0.3218 - val_accuracy: 0.9234 - lr: 3.8742e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2496 - accuracy: 0.9530 - val_loss: 0.3219 - val_accuracy: 0.9218 - lr: 3.4868e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2494 - accuracy: 0.9531 - val_loss: 0.3176 - val_accuracy: 0.9246 - lr: 3.4868e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2467 - accuracy: 0.9538 - val_loss: 0.3241 - val_accuracy: 0.9249 - lr: 3.4868e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2474 - accuracy: 0.9541 - val_loss: 0.3273 - val_accuracy: 0.9212 - lr: 3.4868e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2482 - accuracy: 0.9537 - val_loss: 0.3216 - val_accuracy: 0.9223 - lr: 3.4868e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2441 - accuracy: 0.9570 - val_loss: 0.3239 - val_accuracy: 0.9243 - lr: 3.1381e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2430 - accuracy: 0.9561 - val_loss: 0.3215 - val_accuracy: 0.9224 - lr: 3.1381e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2425 - accuracy: 0.9568 - val_loss: 0.3166 - val_accuracy: 0.9244 - lr: 3.1381e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2415 - accuracy: 0.9573 - val_loss: 0.3194 - val_accuracy: 0.9254 - lr: 3.1381e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2430 - accuracy: 0.9559 - val_loss: 0.3182 - val_accuracy: 0.9266 - lr: 3.1381e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2398 - accuracy: 0.9570 - val_loss: 0.3173 - val_accuracy: 0.9238 - lr: 3.1381e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2405 - accuracy: 0.9563 - val_loss: 0.3154 - val_accuracy: 0.9264 - lr: 2.8243e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2392 - accuracy: 0.9591 - val_loss: 0.3173 - val_accuracy: 0.9225 - lr: 2.8243e-04\n",
            "Epoch 87/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2392 - accuracy: 0.9576 - val_loss: 0.3158 - val_accuracy: 0.9267 - lr: 2.8243e-04\n",
            "Epoch 88/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2382 - accuracy: 0.9589 - val_loss: 0.3174 - val_accuracy: 0.9235 - lr: 2.8243e-04\n",
            "Epoch 89/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2381 - accuracy: 0.9578 - val_loss: 0.3216 - val_accuracy: 0.9232 - lr: 2.5419e-04\n",
            "Epoch 90/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2373 - accuracy: 0.9559 - val_loss: 0.3232 - val_accuracy: 0.9223 - lr: 2.5419e-04\n",
            "Epoch 91/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2370 - accuracy: 0.9569 - val_loss: 0.3122 - val_accuracy: 0.9229 - lr: 2.5419e-04\n",
            "Epoch 92/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2367 - accuracy: 0.9580 - val_loss: 0.3132 - val_accuracy: 0.9249 - lr: 2.5419e-04\n",
            "Epoch 93/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2353 - accuracy: 0.9595 - val_loss: 0.3168 - val_accuracy: 0.9270 - lr: 2.5419e-04\n",
            "Epoch 94/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2348 - accuracy: 0.9598 - val_loss: 0.3159 - val_accuracy: 0.9246 - lr: 2.5419e-04\n",
            "Epoch 95/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2353 - accuracy: 0.9589 - val_loss: 0.3111 - val_accuracy: 0.9267 - lr: 2.2877e-04\n",
            "Epoch 96/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2330 - accuracy: 0.9606 - val_loss: 0.3149 - val_accuracy: 0.9251 - lr: 2.2877e-04\n",
            "Epoch 97/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2338 - accuracy: 0.9602 - val_loss: 0.3162 - val_accuracy: 0.9255 - lr: 2.2877e-04\n",
            "Epoch 98/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2327 - accuracy: 0.9632 - val_loss: 0.3172 - val_accuracy: 0.9237 - lr: 2.2877e-04\n",
            "Epoch 99/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2323 - accuracy: 0.9604 - val_loss: 0.3146 - val_accuracy: 0.9288 - lr: 2.0589e-04\n",
            "Epoch 100/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2304 - accuracy: 0.9610 - val_loss: 0.3160 - val_accuracy: 0.9252 - lr: 2.0589e-04\n",
            "Epoch 101/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2301 - accuracy: 0.9619 - val_loss: 0.3141 - val_accuracy: 0.9281 - lr: 2.0589e-04\n",
            "Epoch 102/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2301 - accuracy: 0.9624 - val_loss: 0.3103 - val_accuracy: 0.9272 - lr: 1.8530e-04\n",
            "Epoch 103/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2285 - accuracy: 0.9641 - val_loss: 0.3105 - val_accuracy: 0.9276 - lr: 1.8530e-04\n",
            "Epoch 104/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2296 - accuracy: 0.9607 - val_loss: 0.3150 - val_accuracy: 0.9282 - lr: 1.8530e-04\n",
            "Epoch 105/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2285 - accuracy: 0.9631 - val_loss: 0.3185 - val_accuracy: 0.9253 - lr: 1.8530e-04\n",
            "Epoch 106/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2272 - accuracy: 0.9647 - val_loss: 0.3120 - val_accuracy: 0.9295 - lr: 1.6677e-04\n",
            "Epoch 107/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2278 - accuracy: 0.9617 - val_loss: 0.3093 - val_accuracy: 0.9290 - lr: 1.6677e-04\n",
            "Epoch 108/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2279 - accuracy: 0.9643 - val_loss: 0.3128 - val_accuracy: 0.9290 - lr: 1.6677e-04\n",
            "Epoch 109/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2271 - accuracy: 0.9640 - val_loss: 0.3086 - val_accuracy: 0.9271 - lr: 1.6677e-04\n",
            "Epoch 110/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2267 - accuracy: 0.9625 - val_loss: 0.3135 - val_accuracy: 0.9258 - lr: 1.6677e-04\n",
            "Epoch 111/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2272 - accuracy: 0.9636 - val_loss: 0.3146 - val_accuracy: 0.9280 - lr: 1.6677e-04\n",
            "Epoch 112/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2263 - accuracy: 0.9653 - val_loss: 0.3124 - val_accuracy: 0.9271 - lr: 1.6677e-04\n",
            "Epoch 113/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2269 - accuracy: 0.9631 - val_loss: 0.3161 - val_accuracy: 0.9278 - lr: 1.5009e-04\n",
            "Epoch 114/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2265 - accuracy: 0.9654 - val_loss: 0.3145 - val_accuracy: 0.9278 - lr: 1.5009e-04\n",
            "Epoch 115/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2262 - accuracy: 0.9631 - val_loss: 0.3131 - val_accuracy: 0.9294 - lr: 1.5009e-04\n",
            "Epoch 116/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2240 - accuracy: 0.9659 - val_loss: 0.3115 - val_accuracy: 0.9278 - lr: 1.3509e-04\n",
            "Epoch 117/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2246 - accuracy: 0.9671 - val_loss: 0.3110 - val_accuracy: 0.9271 - lr: 1.3509e-04\n",
            "Epoch 118/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2247 - accuracy: 0.9647 - val_loss: 0.3130 - val_accuracy: 0.9277 - lr: 1.3509e-04\n",
            "Epoch 119/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2242 - accuracy: 0.9651 - val_loss: 0.3099 - val_accuracy: 0.9250 - lr: 1.2158e-04\n",
            "Epoch 120/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2236 - accuracy: 0.9652 - val_loss: 0.3142 - val_accuracy: 0.9296 - lr: 1.2158e-04\n",
            "Epoch 121/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2241 - accuracy: 0.9651 - val_loss: 0.3116 - val_accuracy: 0.9273 - lr: 1.2158e-04\n",
            "Epoch 122/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2236 - accuracy: 0.9650 - val_loss: 0.3099 - val_accuracy: 0.9298 - lr: 1.0942e-04\n",
            "Epoch 123/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2221 - accuracy: 0.9651 - val_loss: 0.3085 - val_accuracy: 0.9299 - lr: 1.0942e-04\n",
            "Epoch 124/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2226 - accuracy: 0.9655 - val_loss: 0.3085 - val_accuracy: 0.9310 - lr: 1.0942e-04\n",
            "Epoch 125/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2224 - accuracy: 0.9668 - val_loss: 0.3102 - val_accuracy: 0.9299 - lr: 1.0942e-04\n",
            "Epoch 126/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2227 - accuracy: 0.9657 - val_loss: 0.3055 - val_accuracy: 0.9282 - lr: 1.0942e-04\n",
            "Epoch 127/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2214 - accuracy: 0.9664 - val_loss: 0.3084 - val_accuracy: 0.9287 - lr: 1.0942e-04\n",
            "Epoch 128/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2218 - accuracy: 0.9667 - val_loss: 0.3139 - val_accuracy: 0.9274 - lr: 1.0942e-04\n",
            "Epoch 129/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2213 - accuracy: 0.9658 - val_loss: 0.3057 - val_accuracy: 0.9288 - lr: 1.0942e-04\n",
            "Epoch 130/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2220 - accuracy: 0.9664 - val_loss: 0.3068 - val_accuracy: 0.9287 - lr: 9.8477e-05\n",
            "Epoch 131/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2219 - accuracy: 0.9665 - val_loss: 0.3082 - val_accuracy: 0.9282 - lr: 9.8477e-05\n",
            "Epoch 132/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2203 - accuracy: 0.9666 - val_loss: 0.3069 - val_accuracy: 0.9288 - lr: 9.8477e-05\n",
            "Epoch 133/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2199 - accuracy: 0.9662 - val_loss: 0.3093 - val_accuracy: 0.9302 - lr: 8.8629e-05\n",
            "Epoch 134/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2204 - accuracy: 0.9672 - val_loss: 0.3073 - val_accuracy: 0.9322 - lr: 8.8629e-05\n",
            "Epoch 135/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2198 - accuracy: 0.9669 - val_loss: 0.3104 - val_accuracy: 0.9270 - lr: 8.8629e-05\n",
            "Epoch 136/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2193 - accuracy: 0.9673 - val_loss: 0.3063 - val_accuracy: 0.9299 - lr: 7.9766e-05\n",
            "Epoch 137/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2200 - accuracy: 0.9664 - val_loss: 0.3075 - val_accuracy: 0.9304 - lr: 7.9766e-05\n",
            "Epoch 138/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2187 - accuracy: 0.9698 - val_loss: 0.3096 - val_accuracy: 0.9297 - lr: 7.9766e-05\n",
            "Epoch 139/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2197 - accuracy: 0.9667 - val_loss: 0.3105 - val_accuracy: 0.9297 - lr: 7.1790e-05\n",
            "Epoch 140/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2185 - accuracy: 0.9679 - val_loss: 0.3119 - val_accuracy: 0.9317 - lr: 7.1790e-05\n",
            "Epoch 141/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2184 - accuracy: 0.9663 - val_loss: 0.3128 - val_accuracy: 0.9302 - lr: 7.1790e-05\n",
            "Epoch 142/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2187 - accuracy: 0.9664 - val_loss: 0.3106 - val_accuracy: 0.9306 - lr: 6.4611e-05\n",
            "Epoch 143/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2185 - accuracy: 0.9673 - val_loss: 0.3115 - val_accuracy: 0.9286 - lr: 6.4611e-05\n",
            "Epoch 144/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2188 - accuracy: 0.9676 - val_loss: 0.3050 - val_accuracy: 0.9300 - lr: 6.4611e-05\n",
            "Epoch 145/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2170 - accuracy: 0.9693 - val_loss: 0.3105 - val_accuracy: 0.9297 - lr: 6.4611e-05\n",
            "Epoch 146/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2182 - accuracy: 0.9683 - val_loss: 0.3107 - val_accuracy: 0.9301 - lr: 6.4611e-05\n",
            "Epoch 147/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2182 - accuracy: 0.9669 - val_loss: 0.3065 - val_accuracy: 0.9328 - lr: 6.4611e-05\n",
            "Epoch 148/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2173 - accuracy: 0.9689 - val_loss: 0.3084 - val_accuracy: 0.9289 - lr: 5.8150e-05\n",
            "Epoch 149/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2186 - accuracy: 0.9675 - val_loss: 0.3093 - val_accuracy: 0.9300 - lr: 5.8150e-05\n",
            "Epoch 150/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2164 - accuracy: 0.9680 - val_loss: 0.3067 - val_accuracy: 0.9287 - lr: 5.8150e-05\n",
            "Epoch 151/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2178 - accuracy: 0.9680 - val_loss: 0.3070 - val_accuracy: 0.9303 - lr: 5.2335e-05\n",
            "Epoch 152/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2174 - accuracy: 0.9689 - val_loss: 0.3127 - val_accuracy: 0.9299 - lr: 5.2335e-05\n",
            "Epoch 153/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2178 - accuracy: 0.9663 - val_loss: 0.3101 - val_accuracy: 0.9313 - lr: 5.2335e-05\n",
            "Epoch 154/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2164 - accuracy: 0.9691 - val_loss: 0.3104 - val_accuracy: 0.9283 - lr: 4.7101e-05\n",
            "Epoch 155/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2161 - accuracy: 0.9702 - val_loss: 0.3078 - val_accuracy: 0.9290 - lr: 4.7101e-05\n",
            "Epoch 156/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2169 - accuracy: 0.9683 - val_loss: 0.3101 - val_accuracy: 0.9289 - lr: 4.7101e-05\n",
            "Epoch 157/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2163 - accuracy: 0.9689 - val_loss: 0.3103 - val_accuracy: 0.9296 - lr: 4.2391e-05\n",
            "Epoch 158/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2168 - accuracy: 0.9695 - val_loss: 0.3051 - val_accuracy: 0.9310 - lr: 4.2391e-05\n",
            "Epoch 159/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2163 - accuracy: 0.9694 - val_loss: 0.3092 - val_accuracy: 0.9322 - lr: 4.2391e-05\n",
            "Epoch 160/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2172 - accuracy: 0.9666 - val_loss: 0.3089 - val_accuracy: 0.9264 - lr: 3.8152e-05\n",
            "Epoch 161/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2163 - accuracy: 0.9683 - val_loss: 0.3056 - val_accuracy: 0.9317 - lr: 3.8152e-05\n",
            "Epoch 162/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2164 - accuracy: 0.9681 - val_loss: 0.3113 - val_accuracy: 0.9281 - lr: 3.8152e-05\n",
            "Epoch 163/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2158 - accuracy: 0.9695 - val_loss: 0.3079 - val_accuracy: 0.9290 - lr: 3.4337e-05\n",
            "Epoch 164/2000\n",
            "383/383 [==============================] - 4s 11ms/step - loss: 0.2161 - accuracy: 0.9697 - val_loss: 0.3077 - val_accuracy: 0.9308 - lr: 3.4337e-05\n",
            "Epoch 165/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2163 - accuracy: 0.9687 - val_loss: 0.3064 - val_accuracy: 0.9297 - lr: 3.4337e-05\n",
            "Epoch 166/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2151 - accuracy: 0.9686 - val_loss: 0.3097 - val_accuracy: 0.9288 - lr: 3.0903e-05\n",
            "Epoch 167/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2160 - accuracy: 0.9693 - val_loss: 0.3093 - val_accuracy: 0.9281 - lr: 3.0903e-05\n",
            "Epoch 168/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2162 - accuracy: 0.9684 - val_loss: 0.3083 - val_accuracy: 0.9295 - lr: 3.0903e-05\n",
            "Epoch 169/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2163 - accuracy: 0.9703 - val_loss: 0.3087 - val_accuracy: 0.9307 - lr: 2.7813e-05\n",
            "Epoch 170/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2150 - accuracy: 0.9703 - val_loss: 0.3090 - val_accuracy: 0.9282 - lr: 2.7813e-05\n",
            "Epoch 171/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2146 - accuracy: 0.9687 - val_loss: 0.3065 - val_accuracy: 0.9299 - lr: 2.7813e-05\n",
            "Epoch 172/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2154 - accuracy: 0.9702 - val_loss: 0.3126 - val_accuracy: 0.9274 - lr: 2.5032e-05\n",
            "Epoch 173/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2149 - accuracy: 0.9711 - val_loss: 0.3084 - val_accuracy: 0.9294 - lr: 2.5032e-05\n",
            "Epoch 174/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2148 - accuracy: 0.9687 - val_loss: 0.3055 - val_accuracy: 0.9302 - lr: 2.5032e-05\n",
            "Epoch 175/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2156 - accuracy: 0.9697 - val_loss: 0.3062 - val_accuracy: 0.9305 - lr: 2.2528e-05\n",
            "Epoch 176/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2142 - accuracy: 0.9714 - val_loss: 0.3066 - val_accuracy: 0.9320 - lr: 2.2528e-05\n",
            "Epoch 177/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2164 - accuracy: 0.9689 - val_loss: 0.3062 - val_accuracy: 0.9305 - lr: 2.2528e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e700ac2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_zB1OL252B3"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbEZKkhn52B4",
        "outputId": "5cb1c6de-40ff-42f1-c138-c7c1442822f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.895"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KTK643Nkt4E",
        "outputId": "da482a4a-47c5-4871-eba9-70f98b2f1e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 5s 11ms/step - loss: 1.3102 - accuracy: 0.5779 - val_loss: 0.7070 - val_accuracy: 0.7507 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.6338 - accuracy: 0.7814 - val_loss: 0.5697 - val_accuracy: 0.8127 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.5559 - accuracy: 0.8154 - val_loss: 0.5158 - val_accuracy: 0.8337 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.5010 - accuracy: 0.8418 - val_loss: 0.4802 - val_accuracy: 0.8527 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4655 - accuracy: 0.8553 - val_loss: 0.4506 - val_accuracy: 0.8637 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4408 - accuracy: 0.8658 - val_loss: 0.4524 - val_accuracy: 0.8623 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4275 - accuracy: 0.8711 - val_loss: 0.4266 - val_accuracy: 0.8743 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4129 - accuracy: 0.8790 - val_loss: 0.4233 - val_accuracy: 0.8745 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.4019 - accuracy: 0.8853 - val_loss: 0.3994 - val_accuracy: 0.8856 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3895 - accuracy: 0.8876 - val_loss: 0.4112 - val_accuracy: 0.8819 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3878 - accuracy: 0.8892 - val_loss: 0.4001 - val_accuracy: 0.8881 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3785 - accuracy: 0.8917 - val_loss: 0.3945 - val_accuracy: 0.8877 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3714 - accuracy: 0.8966 - val_loss: 0.4042 - val_accuracy: 0.8780 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3725 - accuracy: 0.8962 - val_loss: 0.3906 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3670 - accuracy: 0.8978 - val_loss: 0.3845 - val_accuracy: 0.8943 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3630 - accuracy: 0.8991 - val_loss: 0.3837 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3585 - accuracy: 0.9009 - val_loss: 0.3852 - val_accuracy: 0.8925 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3560 - accuracy: 0.9022 - val_loss: 0.3732 - val_accuracy: 0.9004 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3569 - accuracy: 0.9013 - val_loss: 0.3772 - val_accuracy: 0.8931 - lr: 0.0010\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3460 - accuracy: 0.9051 - val_loss: 0.3695 - val_accuracy: 0.9007 - lr: 0.0010\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3435 - accuracy: 0.9082 - val_loss: 0.3812 - val_accuracy: 0.8971 - lr: 0.0010\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3467 - accuracy: 0.9070 - val_loss: 0.3747 - val_accuracy: 0.8983 - lr: 0.0010\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3426 - accuracy: 0.9088 - val_loss: 0.3763 - val_accuracy: 0.8971 - lr: 0.0010\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3363 - accuracy: 0.9090 - val_loss: 0.3694 - val_accuracy: 0.8987 - lr: 9.0000e-04\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3314 - accuracy: 0.9111 - val_loss: 0.3630 - val_accuracy: 0.9022 - lr: 9.0000e-04\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3307 - accuracy: 0.9110 - val_loss: 0.3692 - val_accuracy: 0.8990 - lr: 9.0000e-04\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3303 - accuracy: 0.9125 - val_loss: 0.3623 - val_accuracy: 0.9039 - lr: 9.0000e-04\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3288 - accuracy: 0.9162 - val_loss: 0.3617 - val_accuracy: 0.9044 - lr: 9.0000e-04\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3238 - accuracy: 0.9159 - val_loss: 0.3616 - val_accuracy: 0.9035 - lr: 9.0000e-04\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3233 - accuracy: 0.9167 - val_loss: 0.3594 - val_accuracy: 0.9031 - lr: 9.0000e-04\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3227 - accuracy: 0.9132 - val_loss: 0.3687 - val_accuracy: 0.8977 - lr: 9.0000e-04\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3240 - accuracy: 0.9164 - val_loss: 0.3590 - val_accuracy: 0.9023 - lr: 9.0000e-04\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3195 - accuracy: 0.9167 - val_loss: 0.3565 - val_accuracy: 0.9063 - lr: 9.0000e-04\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3177 - accuracy: 0.9203 - val_loss: 0.3516 - val_accuracy: 0.9066 - lr: 9.0000e-04\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3160 - accuracy: 0.9201 - val_loss: 0.3710 - val_accuracy: 0.9005 - lr: 9.0000e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3138 - accuracy: 0.9200 - val_loss: 0.3559 - val_accuracy: 0.9040 - lr: 9.0000e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3114 - accuracy: 0.9210 - val_loss: 0.3568 - val_accuracy: 0.9060 - lr: 9.0000e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3071 - accuracy: 0.9230 - val_loss: 0.3592 - val_accuracy: 0.9037 - lr: 8.1000e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3077 - accuracy: 0.9236 - val_loss: 0.3599 - val_accuracy: 0.9022 - lr: 8.1000e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3045 - accuracy: 0.9229 - val_loss: 0.3539 - val_accuracy: 0.9079 - lr: 8.1000e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.3008 - accuracy: 0.9238 - val_loss: 0.3567 - val_accuracy: 0.9020 - lr: 7.2900e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2991 - accuracy: 0.9269 - val_loss: 0.3561 - val_accuracy: 0.9068 - lr: 7.2900e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2971 - accuracy: 0.9281 - val_loss: 0.3578 - val_accuracy: 0.9031 - lr: 7.2900e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2942 - accuracy: 0.9285 - val_loss: 0.3525 - val_accuracy: 0.9090 - lr: 6.5610e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2903 - accuracy: 0.9296 - val_loss: 0.3492 - val_accuracy: 0.9096 - lr: 6.5610e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2899 - accuracy: 0.9301 - val_loss: 0.3467 - val_accuracy: 0.9110 - lr: 6.5610e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2887 - accuracy: 0.9311 - val_loss: 0.3599 - val_accuracy: 0.9090 - lr: 6.5610e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2887 - accuracy: 0.9311 - val_loss: 0.3586 - val_accuracy: 0.9090 - lr: 6.5610e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2877 - accuracy: 0.9325 - val_loss: 0.3457 - val_accuracy: 0.9095 - lr: 6.5610e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2866 - accuracy: 0.9334 - val_loss: 0.3554 - val_accuracy: 0.9069 - lr: 6.5610e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2848 - accuracy: 0.9343 - val_loss: 0.3437 - val_accuracy: 0.9098 - lr: 6.5610e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2844 - accuracy: 0.9322 - val_loss: 0.3524 - val_accuracy: 0.9094 - lr: 6.5610e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2854 - accuracy: 0.9326 - val_loss: 0.3569 - val_accuracy: 0.9053 - lr: 6.5610e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2850 - accuracy: 0.9343 - val_loss: 0.3494 - val_accuracy: 0.9093 - lr: 6.5610e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2793 - accuracy: 0.9364 - val_loss: 0.3500 - val_accuracy: 0.9072 - lr: 5.9049e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2802 - accuracy: 0.9354 - val_loss: 0.3509 - val_accuracy: 0.9067 - lr: 5.9049e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2760 - accuracy: 0.9367 - val_loss: 0.3493 - val_accuracy: 0.9104 - lr: 5.9049e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2739 - accuracy: 0.9393 - val_loss: 0.3458 - val_accuracy: 0.9107 - lr: 5.3144e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2737 - accuracy: 0.9403 - val_loss: 0.3483 - val_accuracy: 0.9110 - lr: 5.3144e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2723 - accuracy: 0.9384 - val_loss: 0.3492 - val_accuracy: 0.9108 - lr: 5.3144e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2714 - accuracy: 0.9425 - val_loss: 0.3476 - val_accuracy: 0.9077 - lr: 4.7830e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2716 - accuracy: 0.9409 - val_loss: 0.3449 - val_accuracy: 0.9118 - lr: 4.7830e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2677 - accuracy: 0.9409 - val_loss: 0.3483 - val_accuracy: 0.9149 - lr: 4.7830e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2664 - accuracy: 0.9420 - val_loss: 0.3463 - val_accuracy: 0.9079 - lr: 4.3047e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2627 - accuracy: 0.9444 - val_loss: 0.3529 - val_accuracy: 0.9076 - lr: 4.3047e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2635 - accuracy: 0.9442 - val_loss: 0.3474 - val_accuracy: 0.9094 - lr: 4.3047e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2619 - accuracy: 0.9445 - val_loss: 0.3427 - val_accuracy: 0.9121 - lr: 3.8742e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2596 - accuracy: 0.9449 - val_loss: 0.3427 - val_accuracy: 0.9125 - lr: 3.8742e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2591 - accuracy: 0.9476 - val_loss: 0.3438 - val_accuracy: 0.9091 - lr: 3.8742e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2600 - accuracy: 0.9466 - val_loss: 0.3460 - val_accuracy: 0.9146 - lr: 3.8742e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2582 - accuracy: 0.9462 - val_loss: 0.3406 - val_accuracy: 0.9121 - lr: 3.4868e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2573 - accuracy: 0.9470 - val_loss: 0.3422 - val_accuracy: 0.9138 - lr: 3.4868e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2556 - accuracy: 0.9496 - val_loss: 0.3464 - val_accuracy: 0.9108 - lr: 3.4868e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2547 - accuracy: 0.9489 - val_loss: 0.3453 - val_accuracy: 0.9117 - lr: 3.4868e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2531 - accuracy: 0.9493 - val_loss: 0.3430 - val_accuracy: 0.9114 - lr: 3.1381e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2525 - accuracy: 0.9508 - val_loss: 0.3459 - val_accuracy: 0.9111 - lr: 3.1381e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2517 - accuracy: 0.9507 - val_loss: 0.3531 - val_accuracy: 0.9113 - lr: 3.1381e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2503 - accuracy: 0.9534 - val_loss: 0.3415 - val_accuracy: 0.9150 - lr: 2.8243e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2493 - accuracy: 0.9493 - val_loss: 0.3412 - val_accuracy: 0.9116 - lr: 2.8243e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2506 - accuracy: 0.9518 - val_loss: 0.3450 - val_accuracy: 0.9162 - lr: 2.8243e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2470 - accuracy: 0.9521 - val_loss: 0.3422 - val_accuracy: 0.9117 - lr: 2.5419e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2471 - accuracy: 0.9522 - val_loss: 0.3433 - val_accuracy: 0.9130 - lr: 2.5419e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2468 - accuracy: 0.9522 - val_loss: 0.3405 - val_accuracy: 0.9133 - lr: 2.5419e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2467 - accuracy: 0.9523 - val_loss: 0.3444 - val_accuracy: 0.9130 - lr: 2.2877e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2456 - accuracy: 0.9533 - val_loss: 0.3416 - val_accuracy: 0.9097 - lr: 2.2877e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2448 - accuracy: 0.9533 - val_loss: 0.3400 - val_accuracy: 0.9143 - lr: 2.2877e-04\n",
            "Epoch 87/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2439 - accuracy: 0.9549 - val_loss: 0.3394 - val_accuracy: 0.9148 - lr: 2.2877e-04\n",
            "Epoch 88/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2429 - accuracy: 0.9538 - val_loss: 0.3394 - val_accuracy: 0.9114 - lr: 2.2877e-04\n",
            "Epoch 89/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2440 - accuracy: 0.9549 - val_loss: 0.3395 - val_accuracy: 0.9130 - lr: 2.2877e-04\n",
            "Epoch 90/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2424 - accuracy: 0.9540 - val_loss: 0.3411 - val_accuracy: 0.9157 - lr: 2.2877e-04\n",
            "Epoch 91/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2416 - accuracy: 0.9555 - val_loss: 0.3461 - val_accuracy: 0.9118 - lr: 2.0589e-04\n",
            "Epoch 92/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2407 - accuracy: 0.9559 - val_loss: 0.3421 - val_accuracy: 0.9158 - lr: 2.0589e-04\n",
            "Epoch 93/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2418 - accuracy: 0.9533 - val_loss: 0.3381 - val_accuracy: 0.9156 - lr: 2.0589e-04\n",
            "Epoch 94/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2409 - accuracy: 0.9562 - val_loss: 0.3400 - val_accuracy: 0.9128 - lr: 2.0589e-04\n",
            "Epoch 95/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2411 - accuracy: 0.9560 - val_loss: 0.3379 - val_accuracy: 0.9140 - lr: 2.0589e-04\n",
            "Epoch 96/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2391 - accuracy: 0.9570 - val_loss: 0.3421 - val_accuracy: 0.9140 - lr: 2.0589e-04\n",
            "Epoch 97/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2389 - accuracy: 0.9570 - val_loss: 0.3432 - val_accuracy: 0.9129 - lr: 2.0589e-04\n",
            "Epoch 98/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2391 - accuracy: 0.9562 - val_loss: 0.3425 - val_accuracy: 0.9106 - lr: 2.0589e-04\n",
            "Epoch 99/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2379 - accuracy: 0.9567 - val_loss: 0.3414 - val_accuracy: 0.9144 - lr: 1.8530e-04\n",
            "Epoch 100/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2366 - accuracy: 0.9576 - val_loss: 0.3462 - val_accuracy: 0.9142 - lr: 1.8530e-04\n",
            "Epoch 101/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2379 - accuracy: 0.9572 - val_loss: 0.3420 - val_accuracy: 0.9156 - lr: 1.8530e-04\n",
            "Epoch 102/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2368 - accuracy: 0.9579 - val_loss: 0.3411 - val_accuracy: 0.9130 - lr: 1.6677e-04\n",
            "Epoch 103/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2355 - accuracy: 0.9574 - val_loss: 0.3390 - val_accuracy: 0.9171 - lr: 1.6677e-04\n",
            "Epoch 104/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2355 - accuracy: 0.9593 - val_loss: 0.3434 - val_accuracy: 0.9109 - lr: 1.6677e-04\n",
            "Epoch 105/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2347 - accuracy: 0.9601 - val_loss: 0.3378 - val_accuracy: 0.9120 - lr: 1.5009e-04\n",
            "Epoch 106/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2349 - accuracy: 0.9587 - val_loss: 0.3441 - val_accuracy: 0.9150 - lr: 1.5009e-04\n",
            "Epoch 107/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2338 - accuracy: 0.9600 - val_loss: 0.3378 - val_accuracy: 0.9168 - lr: 1.5009e-04\n",
            "Epoch 108/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2340 - accuracy: 0.9596 - val_loss: 0.3411 - val_accuracy: 0.9171 - lr: 1.3509e-04\n",
            "Epoch 109/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2329 - accuracy: 0.9588 - val_loss: 0.3346 - val_accuracy: 0.9115 - lr: 1.3509e-04\n",
            "Epoch 110/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2336 - accuracy: 0.9611 - val_loss: 0.3357 - val_accuracy: 0.9146 - lr: 1.3509e-04\n",
            "Epoch 111/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2317 - accuracy: 0.9608 - val_loss: 0.3413 - val_accuracy: 0.9137 - lr: 1.3509e-04\n",
            "Epoch 112/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2321 - accuracy: 0.9613 - val_loss: 0.3390 - val_accuracy: 0.9157 - lr: 1.3509e-04\n",
            "Epoch 113/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2314 - accuracy: 0.9618 - val_loss: 0.3394 - val_accuracy: 0.9147 - lr: 1.2158e-04\n",
            "Epoch 114/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2312 - accuracy: 0.9597 - val_loss: 0.3403 - val_accuracy: 0.9132 - lr: 1.2158e-04\n",
            "Epoch 115/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2303 - accuracy: 0.9619 - val_loss: 0.3405 - val_accuracy: 0.9151 - lr: 1.2158e-04\n",
            "Epoch 116/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2322 - accuracy: 0.9585 - val_loss: 0.3394 - val_accuracy: 0.9132 - lr: 1.0942e-04\n",
            "Epoch 117/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2315 - accuracy: 0.9592 - val_loss: 0.3424 - val_accuracy: 0.9140 - lr: 1.0942e-04\n",
            "Epoch 118/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2320 - accuracy: 0.9602 - val_loss: 0.3466 - val_accuracy: 0.9131 - lr: 1.0942e-04\n",
            "Epoch 119/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2300 - accuracy: 0.9604 - val_loss: 0.3363 - val_accuracy: 0.9170 - lr: 9.8477e-05\n",
            "Epoch 120/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2290 - accuracy: 0.9620 - val_loss: 0.3390 - val_accuracy: 0.9148 - lr: 9.8477e-05\n",
            "Epoch 121/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2294 - accuracy: 0.9605 - val_loss: 0.3371 - val_accuracy: 0.9162 - lr: 9.8477e-05\n",
            "Epoch 122/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2295 - accuracy: 0.9613 - val_loss: 0.3375 - val_accuracy: 0.9151 - lr: 8.8629e-05\n",
            "Epoch 123/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2292 - accuracy: 0.9609 - val_loss: 0.3371 - val_accuracy: 0.9137 - lr: 8.8629e-05\n",
            "Epoch 124/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2287 - accuracy: 0.9625 - val_loss: 0.3362 - val_accuracy: 0.9134 - lr: 8.8629e-05\n",
            "Epoch 125/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2274 - accuracy: 0.9640 - val_loss: 0.3401 - val_accuracy: 0.9132 - lr: 7.9766e-05\n",
            "Epoch 126/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2287 - accuracy: 0.9622 - val_loss: 0.3396 - val_accuracy: 0.9143 - lr: 7.9766e-05\n",
            "Epoch 127/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2272 - accuracy: 0.9643 - val_loss: 0.3393 - val_accuracy: 0.9139 - lr: 7.9766e-05\n",
            "Epoch 128/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2284 - accuracy: 0.9617 - val_loss: 0.3373 - val_accuracy: 0.9179 - lr: 7.1790e-05\n",
            "Epoch 129/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2286 - accuracy: 0.9627 - val_loss: 0.3404 - val_accuracy: 0.9162 - lr: 7.1790e-05\n",
            "Epoch 130/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2276 - accuracy: 0.9617 - val_loss: 0.3411 - val_accuracy: 0.9121 - lr: 7.1790e-05\n",
            "Epoch 131/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2277 - accuracy: 0.9627 - val_loss: 0.3406 - val_accuracy: 0.9147 - lr: 6.4611e-05\n",
            "Epoch 132/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2261 - accuracy: 0.9636 - val_loss: 0.3389 - val_accuracy: 0.9149 - lr: 6.4611e-05\n",
            "Epoch 133/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2269 - accuracy: 0.9635 - val_loss: 0.3363 - val_accuracy: 0.9130 - lr: 6.4611e-05\n",
            "Epoch 134/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2272 - accuracy: 0.9620 - val_loss: 0.3419 - val_accuracy: 0.9144 - lr: 5.8150e-05\n",
            "Epoch 135/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2271 - accuracy: 0.9616 - val_loss: 0.3391 - val_accuracy: 0.9142 - lr: 5.8150e-05\n",
            "Epoch 136/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2269 - accuracy: 0.9619 - val_loss: 0.3408 - val_accuracy: 0.9129 - lr: 5.8150e-05\n",
            "Epoch 137/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2248 - accuracy: 0.9648 - val_loss: 0.3350 - val_accuracy: 0.9151 - lr: 5.2335e-05\n",
            "Epoch 138/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2266 - accuracy: 0.9622 - val_loss: 0.3391 - val_accuracy: 0.9156 - lr: 5.2335e-05\n",
            "Epoch 139/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2261 - accuracy: 0.9630 - val_loss: 0.3417 - val_accuracy: 0.9135 - lr: 5.2335e-05\n",
            "Epoch 140/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2264 - accuracy: 0.9619 - val_loss: 0.3373 - val_accuracy: 0.9169 - lr: 4.7101e-05\n",
            "Epoch 141/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2251 - accuracy: 0.9639 - val_loss: 0.3368 - val_accuracy: 0.9148 - lr: 4.7101e-05\n",
            "Epoch 142/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2256 - accuracy: 0.9631 - val_loss: 0.3409 - val_accuracy: 0.9110 - lr: 4.7101e-05\n",
            "Epoch 143/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2259 - accuracy: 0.9624 - val_loss: 0.3479 - val_accuracy: 0.9110 - lr: 4.2391e-05\n",
            "Epoch 144/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2252 - accuracy: 0.9644 - val_loss: 0.3422 - val_accuracy: 0.9145 - lr: 4.2391e-05\n",
            "Epoch 145/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2267 - accuracy: 0.9628 - val_loss: 0.3413 - val_accuracy: 0.9143 - lr: 4.2391e-05\n",
            "Epoch 146/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2249 - accuracy: 0.9641 - val_loss: 0.3434 - val_accuracy: 0.9138 - lr: 3.8152e-05\n",
            "Epoch 147/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2264 - accuracy: 0.9639 - val_loss: 0.3418 - val_accuracy: 0.9114 - lr: 3.8152e-05\n",
            "Epoch 148/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2260 - accuracy: 0.9624 - val_loss: 0.3389 - val_accuracy: 0.9160 - lr: 3.8152e-05\n",
            "Epoch 149/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2247 - accuracy: 0.9635 - val_loss: 0.3388 - val_accuracy: 0.9137 - lr: 3.4337e-05\n",
            "Epoch 150/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2247 - accuracy: 0.9650 - val_loss: 0.3371 - val_accuracy: 0.9132 - lr: 3.4337e-05\n",
            "Epoch 151/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2247 - accuracy: 0.9636 - val_loss: 0.3376 - val_accuracy: 0.9140 - lr: 3.4337e-05\n",
            "Epoch 152/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2246 - accuracy: 0.9634 - val_loss: 0.3396 - val_accuracy: 0.9142 - lr: 3.0903e-05\n",
            "Epoch 153/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2242 - accuracy: 0.9641 - val_loss: 0.3365 - val_accuracy: 0.9161 - lr: 3.0903e-05\n",
            "Epoch 154/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2257 - accuracy: 0.9634 - val_loss: 0.3368 - val_accuracy: 0.9149 - lr: 3.0903e-05\n",
            "Epoch 155/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2235 - accuracy: 0.9635 - val_loss: 0.3375 - val_accuracy: 0.9135 - lr: 2.7813e-05\n",
            "Epoch 156/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2244 - accuracy: 0.9642 - val_loss: 0.3373 - val_accuracy: 0.9178 - lr: 2.7813e-05\n",
            "Epoch 157/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2243 - accuracy: 0.9639 - val_loss: 0.3402 - val_accuracy: 0.9157 - lr: 2.7813e-05\n",
            "Epoch 158/2000\n",
            "383/383 [==============================] - 4s 10ms/step - loss: 0.2238 - accuracy: 0.9636 - val_loss: 0.3382 - val_accuracy: 0.9132 - lr: 2.5032e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0efe2442d0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d3W-766kt4H"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it79cIfekt4H",
        "outputId": "6ebedc74-2c77-44a8-ad93-5d667eb10dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8908"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kdx4FDw7ED"
      },
      "source": [
        "# 남은 데이터 라벨링하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8F_ifi6w9Uq"
      },
      "outputs": [],
      "source": [
        "model1 = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model2 = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74E6i_eCxCNG"
      },
      "outputs": [],
      "source": [
        "unlab_label_1 = model1.predict(unlab_data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tz_MEzhxXos"
      },
      "outputs": [],
      "source": [
        "unlab_label_2 = model2.predict(unlab_data_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiz6rZkT5ORw"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data_1, unlab_data_1], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels_1, unlab_label_1], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIe8iZLkD8pJ"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data_2, unlab_data_2], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels_2, unlab_label_2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru605cBREQ_8",
        "outputId": "f253523a-77a0-4a7a-b781-4ff92031ad92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "657/657 [==============================] - 8s 11ms/step - loss: 1.0349 - accuracy: 0.6429 - val_loss: 0.6362 - val_accuracy: 0.7989 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.5660 - accuracy: 0.8134 - val_loss: 0.5578 - val_accuracy: 0.8264 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.5058 - accuracy: 0.8400 - val_loss: 0.4932 - val_accuracy: 0.8588 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.4663 - accuracy: 0.8589 - val_loss: 0.4715 - val_accuracy: 0.8762 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.4360 - accuracy: 0.8760 - val_loss: 0.4621 - val_accuracy: 0.8806 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.4188 - accuracy: 0.8819 - val_loss: 0.4362 - val_accuracy: 0.8884 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.4075 - accuracy: 0.8878 - val_loss: 0.4221 - val_accuracy: 0.8981 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3945 - accuracy: 0.8931 - val_loss: 0.4406 - val_accuracy: 0.8882 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3879 - accuracy: 0.8967 - val_loss: 0.4203 - val_accuracy: 0.8972 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3824 - accuracy: 0.8983 - val_loss: 0.4495 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3804 - accuracy: 0.8999 - val_loss: 0.4114 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3739 - accuracy: 0.9029 - val_loss: 0.4107 - val_accuracy: 0.9036 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3653 - accuracy: 0.9057 - val_loss: 0.4149 - val_accuracy: 0.9018 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3657 - accuracy: 0.9074 - val_loss: 0.4064 - val_accuracy: 0.9073 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3645 - accuracy: 0.9076 - val_loss: 0.3977 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "657/657 [==============================] - 8s 12ms/step - loss: 0.3595 - accuracy: 0.9079 - val_loss: 0.4338 - val_accuracy: 0.8896 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3605 - accuracy: 0.9070 - val_loss: 0.4013 - val_accuracy: 0.9097 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3547 - accuracy: 0.9111 - val_loss: 0.4021 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3479 - accuracy: 0.9132 - val_loss: 0.4032 - val_accuracy: 0.9084 - lr: 9.0000e-04\n",
            "Epoch 20/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3445 - accuracy: 0.9140 - val_loss: 0.3989 - val_accuracy: 0.9122 - lr: 9.0000e-04\n",
            "Epoch 21/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3432 - accuracy: 0.9144 - val_loss: 0.3947 - val_accuracy: 0.9125 - lr: 9.0000e-04\n",
            "Epoch 22/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3464 - accuracy: 0.9144 - val_loss: 0.4070 - val_accuracy: 0.9089 - lr: 9.0000e-04\n",
            "Epoch 23/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3423 - accuracy: 0.9140 - val_loss: 0.3984 - val_accuracy: 0.9092 - lr: 9.0000e-04\n",
            "Epoch 24/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3396 - accuracy: 0.9179 - val_loss: 0.3976 - val_accuracy: 0.9098 - lr: 9.0000e-04\n",
            "Epoch 25/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3363 - accuracy: 0.9189 - val_loss: 0.3916 - val_accuracy: 0.9143 - lr: 8.1000e-04\n",
            "Epoch 26/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3355 - accuracy: 0.9193 - val_loss: 0.3916 - val_accuracy: 0.9160 - lr: 8.1000e-04\n",
            "Epoch 27/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3305 - accuracy: 0.9207 - val_loss: 0.3888 - val_accuracy: 0.9130 - lr: 8.1000e-04\n",
            "Epoch 28/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3321 - accuracy: 0.9215 - val_loss: 0.3890 - val_accuracy: 0.9139 - lr: 8.1000e-04\n",
            "Epoch 29/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3265 - accuracy: 0.9217 - val_loss: 0.3850 - val_accuracy: 0.9169 - lr: 8.1000e-04\n",
            "Epoch 30/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3255 - accuracy: 0.9227 - val_loss: 0.3844 - val_accuracy: 0.9203 - lr: 8.1000e-04\n",
            "Epoch 31/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3250 - accuracy: 0.9235 - val_loss: 0.3862 - val_accuracy: 0.9177 - lr: 8.1000e-04\n",
            "Epoch 32/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3284 - accuracy: 0.9226 - val_loss: 0.3794 - val_accuracy: 0.9196 - lr: 8.1000e-04\n",
            "Epoch 33/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3231 - accuracy: 0.9250 - val_loss: 0.3897 - val_accuracy: 0.9161 - lr: 8.1000e-04\n",
            "Epoch 34/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3239 - accuracy: 0.9242 - val_loss: 0.3905 - val_accuracy: 0.9145 - lr: 8.1000e-04\n",
            "Epoch 35/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3224 - accuracy: 0.9264 - val_loss: 0.3840 - val_accuracy: 0.9191 - lr: 8.1000e-04\n",
            "Epoch 36/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3166 - accuracy: 0.9279 - val_loss: 0.3848 - val_accuracy: 0.9203 - lr: 7.2900e-04\n",
            "Epoch 37/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3189 - accuracy: 0.9262 - val_loss: 0.3813 - val_accuracy: 0.9176 - lr: 7.2900e-04\n",
            "Epoch 38/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3157 - accuracy: 0.9278 - val_loss: 0.3753 - val_accuracy: 0.9198 - lr: 7.2900e-04\n",
            "Epoch 39/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3156 - accuracy: 0.9295 - val_loss: 0.3778 - val_accuracy: 0.9213 - lr: 7.2900e-04\n",
            "Epoch 40/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3135 - accuracy: 0.9290 - val_loss: 0.3792 - val_accuracy: 0.9229 - lr: 7.2900e-04\n",
            "Epoch 41/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3122 - accuracy: 0.9289 - val_loss: 0.3781 - val_accuracy: 0.9200 - lr: 7.2900e-04\n",
            "Epoch 42/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3099 - accuracy: 0.9312 - val_loss: 0.3746 - val_accuracy: 0.9222 - lr: 6.5610e-04\n",
            "Epoch 43/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3071 - accuracy: 0.9320 - val_loss: 0.3788 - val_accuracy: 0.9213 - lr: 6.5610e-04\n",
            "Epoch 44/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3101 - accuracy: 0.9308 - val_loss: 0.3776 - val_accuracy: 0.9195 - lr: 6.5610e-04\n",
            "Epoch 45/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3040 - accuracy: 0.9335 - val_loss: 0.3768 - val_accuracy: 0.9241 - lr: 6.5610e-04\n",
            "Epoch 46/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3033 - accuracy: 0.9340 - val_loss: 0.3713 - val_accuracy: 0.9253 - lr: 5.9049e-04\n",
            "Epoch 47/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3011 - accuracy: 0.9339 - val_loss: 0.3764 - val_accuracy: 0.9236 - lr: 5.9049e-04\n",
            "Epoch 48/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3015 - accuracy: 0.9347 - val_loss: 0.3750 - val_accuracy: 0.9218 - lr: 5.9049e-04\n",
            "Epoch 49/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3002 - accuracy: 0.9348 - val_loss: 0.3733 - val_accuracy: 0.9253 - lr: 5.9049e-04\n",
            "Epoch 50/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2971 - accuracy: 0.9364 - val_loss: 0.3712 - val_accuracy: 0.9242 - lr: 5.3144e-04\n",
            "Epoch 51/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2976 - accuracy: 0.9374 - val_loss: 0.3719 - val_accuracy: 0.9240 - lr: 5.3144e-04\n",
            "Epoch 52/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2941 - accuracy: 0.9384 - val_loss: 0.3702 - val_accuracy: 0.9244 - lr: 5.3144e-04\n",
            "Epoch 53/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2943 - accuracy: 0.9386 - val_loss: 0.3730 - val_accuracy: 0.9252 - lr: 5.3144e-04\n",
            "Epoch 54/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2925 - accuracy: 0.9382 - val_loss: 0.3677 - val_accuracy: 0.9264 - lr: 5.3144e-04\n",
            "Epoch 55/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2910 - accuracy: 0.9391 - val_loss: 0.3702 - val_accuracy: 0.9233 - lr: 5.3144e-04\n",
            "Epoch 56/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2920 - accuracy: 0.9385 - val_loss: 0.3670 - val_accuracy: 0.9262 - lr: 5.3144e-04\n",
            "Epoch 57/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2920 - accuracy: 0.9393 - val_loss: 0.3730 - val_accuracy: 0.9249 - lr: 5.3144e-04\n",
            "Epoch 58/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2899 - accuracy: 0.9392 - val_loss: 0.3688 - val_accuracy: 0.9252 - lr: 5.3144e-04\n",
            "Epoch 59/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2910 - accuracy: 0.9398 - val_loss: 0.3684 - val_accuracy: 0.9271 - lr: 5.3144e-04\n",
            "Epoch 60/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2865 - accuracy: 0.9415 - val_loss: 0.3647 - val_accuracy: 0.9273 - lr: 4.7830e-04\n",
            "Epoch 61/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2865 - accuracy: 0.9410 - val_loss: 0.3661 - val_accuracy: 0.9257 - lr: 4.7830e-04\n",
            "Epoch 62/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2862 - accuracy: 0.9421 - val_loss: 0.3632 - val_accuracy: 0.9273 - lr: 4.7830e-04\n",
            "Epoch 63/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2841 - accuracy: 0.9431 - val_loss: 0.3657 - val_accuracy: 0.9278 - lr: 4.7830e-04\n",
            "Epoch 64/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2824 - accuracy: 0.9441 - val_loss: 0.3656 - val_accuracy: 0.9259 - lr: 4.7830e-04\n",
            "Epoch 65/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2821 - accuracy: 0.9440 - val_loss: 0.3645 - val_accuracy: 0.9300 - lr: 4.7830e-04\n",
            "Epoch 66/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2825 - accuracy: 0.9432 - val_loss: 0.3630 - val_accuracy: 0.9305 - lr: 4.3047e-04\n",
            "Epoch 67/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2828 - accuracy: 0.9436 - val_loss: 0.3631 - val_accuracy: 0.9291 - lr: 4.3047e-04\n",
            "Epoch 68/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2809 - accuracy: 0.9440 - val_loss: 0.3626 - val_accuracy: 0.9302 - lr: 4.3047e-04\n",
            "Epoch 69/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2796 - accuracy: 0.9463 - val_loss: 0.3612 - val_accuracy: 0.9288 - lr: 4.3047e-04\n",
            "Epoch 70/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2784 - accuracy: 0.9451 - val_loss: 0.3621 - val_accuracy: 0.9319 - lr: 4.3047e-04\n",
            "Epoch 71/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2800 - accuracy: 0.9465 - val_loss: 0.3661 - val_accuracy: 0.9269 - lr: 4.3047e-04\n",
            "Epoch 72/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2784 - accuracy: 0.9453 - val_loss: 0.3638 - val_accuracy: 0.9308 - lr: 4.3047e-04\n",
            "Epoch 73/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2772 - accuracy: 0.9450 - val_loss: 0.3637 - val_accuracy: 0.9294 - lr: 3.8742e-04\n",
            "Epoch 74/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2764 - accuracy: 0.9468 - val_loss: 0.3625 - val_accuracy: 0.9301 - lr: 3.8742e-04\n",
            "Epoch 75/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2757 - accuracy: 0.9464 - val_loss: 0.3637 - val_accuracy: 0.9282 - lr: 3.8742e-04\n",
            "Epoch 76/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2738 - accuracy: 0.9480 - val_loss: 0.3588 - val_accuracy: 0.9306 - lr: 3.4868e-04\n",
            "Epoch 77/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2719 - accuracy: 0.9505 - val_loss: 0.3589 - val_accuracy: 0.9309 - lr: 3.4868e-04\n",
            "Epoch 78/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2707 - accuracy: 0.9493 - val_loss: 0.3649 - val_accuracy: 0.9273 - lr: 3.4868e-04\n",
            "Epoch 79/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2712 - accuracy: 0.9490 - val_loss: 0.3612 - val_accuracy: 0.9303 - lr: 3.4868e-04\n",
            "Epoch 80/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2700 - accuracy: 0.9493 - val_loss: 0.3599 - val_accuracy: 0.9311 - lr: 3.1381e-04\n",
            "Epoch 81/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2688 - accuracy: 0.9492 - val_loss: 0.3604 - val_accuracy: 0.9299 - lr: 3.1381e-04\n",
            "Epoch 82/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2688 - accuracy: 0.9502 - val_loss: 0.3616 - val_accuracy: 0.9308 - lr: 3.1381e-04\n",
            "Epoch 83/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2669 - accuracy: 0.9496 - val_loss: 0.3589 - val_accuracy: 0.9283 - lr: 2.8243e-04\n",
            "Epoch 84/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2673 - accuracy: 0.9512 - val_loss: 0.3583 - val_accuracy: 0.9299 - lr: 2.8243e-04\n",
            "Epoch 85/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2667 - accuracy: 0.9526 - val_loss: 0.3605 - val_accuracy: 0.9291 - lr: 2.8243e-04\n",
            "Epoch 86/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2658 - accuracy: 0.9510 - val_loss: 0.3559 - val_accuracy: 0.9319 - lr: 2.8243e-04\n",
            "Epoch 87/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2656 - accuracy: 0.9520 - val_loss: 0.3585 - val_accuracy: 0.9313 - lr: 2.8243e-04\n",
            "Epoch 88/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2656 - accuracy: 0.9516 - val_loss: 0.3580 - val_accuracy: 0.9334 - lr: 2.8243e-04\n",
            "Epoch 89/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2651 - accuracy: 0.9525 - val_loss: 0.3561 - val_accuracy: 0.9313 - lr: 2.8243e-04\n",
            "Epoch 90/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2638 - accuracy: 0.9515 - val_loss: 0.3595 - val_accuracy: 0.9306 - lr: 2.5419e-04\n",
            "Epoch 91/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2623 - accuracy: 0.9529 - val_loss: 0.3588 - val_accuracy: 0.9328 - lr: 2.5419e-04\n",
            "Epoch 92/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2617 - accuracy: 0.9531 - val_loss: 0.3600 - val_accuracy: 0.9322 - lr: 2.5419e-04\n",
            "Epoch 93/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2616 - accuracy: 0.9531 - val_loss: 0.3554 - val_accuracy: 0.9327 - lr: 2.2877e-04\n",
            "Epoch 94/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2614 - accuracy: 0.9520 - val_loss: 0.3550 - val_accuracy: 0.9311 - lr: 2.2877e-04\n",
            "Epoch 95/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2601 - accuracy: 0.9534 - val_loss: 0.3542 - val_accuracy: 0.9319 - lr: 2.2877e-04\n",
            "Epoch 96/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2605 - accuracy: 0.9554 - val_loss: 0.3571 - val_accuracy: 0.9348 - lr: 2.2877e-04\n",
            "Epoch 97/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2609 - accuracy: 0.9528 - val_loss: 0.3578 - val_accuracy: 0.9330 - lr: 2.2877e-04\n",
            "Epoch 98/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2592 - accuracy: 0.9554 - val_loss: 0.3551 - val_accuracy: 0.9324 - lr: 2.2877e-04\n",
            "Epoch 99/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2575 - accuracy: 0.9551 - val_loss: 0.3552 - val_accuracy: 0.9323 - lr: 2.0589e-04\n",
            "Epoch 100/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2582 - accuracy: 0.9558 - val_loss: 0.3549 - val_accuracy: 0.9324 - lr: 2.0589e-04\n",
            "Epoch 101/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2578 - accuracy: 0.9548 - val_loss: 0.3533 - val_accuracy: 0.9350 - lr: 2.0589e-04\n",
            "Epoch 102/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2583 - accuracy: 0.9551 - val_loss: 0.3556 - val_accuracy: 0.9323 - lr: 2.0589e-04\n",
            "Epoch 103/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2584 - accuracy: 0.9553 - val_loss: 0.3560 - val_accuracy: 0.9309 - lr: 2.0589e-04\n",
            "Epoch 104/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2566 - accuracy: 0.9561 - val_loss: 0.3519 - val_accuracy: 0.9374 - lr: 2.0589e-04\n",
            "Epoch 105/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2569 - accuracy: 0.9555 - val_loss: 0.3543 - val_accuracy: 0.9335 - lr: 2.0589e-04\n",
            "Epoch 106/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2555 - accuracy: 0.9571 - val_loss: 0.3546 - val_accuracy: 0.9334 - lr: 2.0589e-04\n",
            "Epoch 107/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2559 - accuracy: 0.9572 - val_loss: 0.3553 - val_accuracy: 0.9337 - lr: 2.0589e-04\n",
            "Epoch 108/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2552 - accuracy: 0.9570 - val_loss: 0.3550 - val_accuracy: 0.9334 - lr: 1.8530e-04\n",
            "Epoch 109/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2549 - accuracy: 0.9557 - val_loss: 0.3561 - val_accuracy: 0.9307 - lr: 1.8530e-04\n",
            "Epoch 110/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2551 - accuracy: 0.9569 - val_loss: 0.3561 - val_accuracy: 0.9334 - lr: 1.8530e-04\n",
            "Epoch 111/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2537 - accuracy: 0.9558 - val_loss: 0.3543 - val_accuracy: 0.9321 - lr: 1.6677e-04\n",
            "Epoch 112/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2532 - accuracy: 0.9581 - val_loss: 0.3538 - val_accuracy: 0.9329 - lr: 1.6677e-04\n",
            "Epoch 113/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2537 - accuracy: 0.9568 - val_loss: 0.3550 - val_accuracy: 0.9324 - lr: 1.6677e-04\n",
            "Epoch 114/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2519 - accuracy: 0.9597 - val_loss: 0.3542 - val_accuracy: 0.9353 - lr: 1.5009e-04\n",
            "Epoch 115/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2533 - accuracy: 0.9580 - val_loss: 0.3534 - val_accuracy: 0.9320 - lr: 1.5009e-04\n",
            "Epoch 116/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2519 - accuracy: 0.9599 - val_loss: 0.3545 - val_accuracy: 0.9334 - lr: 1.5009e-04\n",
            "Epoch 117/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2519 - accuracy: 0.9579 - val_loss: 0.3550 - val_accuracy: 0.9341 - lr: 1.3509e-04\n",
            "Epoch 118/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2509 - accuracy: 0.9594 - val_loss: 0.3542 - val_accuracy: 0.9334 - lr: 1.3509e-04\n",
            "Epoch 119/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2517 - accuracy: 0.9594 - val_loss: 0.3530 - val_accuracy: 0.9344 - lr: 1.3509e-04\n",
            "Epoch 120/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2503 - accuracy: 0.9593 - val_loss: 0.3533 - val_accuracy: 0.9349 - lr: 1.2158e-04\n",
            "Epoch 121/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2508 - accuracy: 0.9589 - val_loss: 0.3538 - val_accuracy: 0.9336 - lr: 1.2158e-04\n",
            "Epoch 122/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2503 - accuracy: 0.9594 - val_loss: 0.3541 - val_accuracy: 0.9332 - lr: 1.2158e-04\n",
            "Epoch 123/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2493 - accuracy: 0.9593 - val_loss: 0.3510 - val_accuracy: 0.9339 - lr: 1.0942e-04\n",
            "Epoch 124/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2495 - accuracy: 0.9602 - val_loss: 0.3531 - val_accuracy: 0.9323 - lr: 1.0942e-04\n",
            "Epoch 125/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2486 - accuracy: 0.9603 - val_loss: 0.3527 - val_accuracy: 0.9360 - lr: 1.0942e-04\n",
            "Epoch 126/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2496 - accuracy: 0.9589 - val_loss: 0.3519 - val_accuracy: 0.9342 - lr: 1.0942e-04\n",
            "Epoch 127/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2486 - accuracy: 0.9600 - val_loss: 0.3533 - val_accuracy: 0.9313 - lr: 9.8477e-05\n",
            "Epoch 128/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2483 - accuracy: 0.9606 - val_loss: 0.3491 - val_accuracy: 0.9343 - lr: 9.8477e-05\n",
            "Epoch 129/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2474 - accuracy: 0.9613 - val_loss: 0.3521 - val_accuracy: 0.9345 - lr: 9.8477e-05\n",
            "Epoch 130/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2493 - accuracy: 0.9594 - val_loss: 0.3505 - val_accuracy: 0.9316 - lr: 9.8477e-05\n",
            "Epoch 131/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2481 - accuracy: 0.9604 - val_loss: 0.3490 - val_accuracy: 0.9349 - lr: 9.8477e-05\n",
            "Epoch 132/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2478 - accuracy: 0.9596 - val_loss: 0.3484 - val_accuracy: 0.9358 - lr: 8.8629e-05\n",
            "Epoch 133/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2480 - accuracy: 0.9596 - val_loss: 0.3502 - val_accuracy: 0.9344 - lr: 8.8629e-05\n",
            "Epoch 134/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2471 - accuracy: 0.9603 - val_loss: 0.3519 - val_accuracy: 0.9346 - lr: 8.8629e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e0cf71f90>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuG_m7tXEi2g"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDtQKCLqElcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e90a68-44be-4188-9c07-123c246698ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8952"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn3.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJwnKwlXEVf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d194acc3-e027-4024-db1c-31a4b25af6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "657/657 [==============================] - 8s 11ms/step - loss: 1.0688 - accuracy: 0.6314 - val_loss: 0.6529 - val_accuracy: 0.7936 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.5860 - accuracy: 0.8049 - val_loss: 0.5950 - val_accuracy: 0.8197 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.5214 - accuracy: 0.8291 - val_loss: 0.5220 - val_accuracy: 0.8512 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.4783 - accuracy: 0.8530 - val_loss: 0.4864 - val_accuracy: 0.8728 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.4484 - accuracy: 0.8699 - val_loss: 0.4764 - val_accuracy: 0.8792 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.4260 - accuracy: 0.8772 - val_loss: 0.4519 - val_accuracy: 0.8859 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.4166 - accuracy: 0.8819 - val_loss: 0.4441 - val_accuracy: 0.8887 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.4078 - accuracy: 0.8865 - val_loss: 0.4440 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3984 - accuracy: 0.8913 - val_loss: 0.4384 - val_accuracy: 0.8937 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3932 - accuracy: 0.8922 - val_loss: 0.4271 - val_accuracy: 0.9011 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3881 - accuracy: 0.8945 - val_loss: 0.4356 - val_accuracy: 0.8978 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3850 - accuracy: 0.8980 - val_loss: 0.4219 - val_accuracy: 0.8992 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3761 - accuracy: 0.9014 - val_loss: 0.4179 - val_accuracy: 0.9047 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3756 - accuracy: 0.9012 - val_loss: 0.4159 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3696 - accuracy: 0.9022 - val_loss: 0.4225 - val_accuracy: 0.9007 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3728 - accuracy: 0.9026 - val_loss: 0.4202 - val_accuracy: 0.9021 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3693 - accuracy: 0.9046 - val_loss: 0.4044 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3656 - accuracy: 0.9039 - val_loss: 0.4073 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3623 - accuracy: 0.9044 - val_loss: 0.4049 - val_accuracy: 0.9083 - lr: 0.0010\n",
            "Epoch 20/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3633 - accuracy: 0.9053 - val_loss: 0.4134 - val_accuracy: 0.9076 - lr: 0.0010\n",
            "Epoch 21/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3554 - accuracy: 0.9086 - val_loss: 0.4068 - val_accuracy: 0.9076 - lr: 9.0000e-04\n",
            "Epoch 22/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3549 - accuracy: 0.9097 - val_loss: 0.3987 - val_accuracy: 0.9097 - lr: 9.0000e-04\n",
            "Epoch 23/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3537 - accuracy: 0.9105 - val_loss: 0.4031 - val_accuracy: 0.9113 - lr: 9.0000e-04\n",
            "Epoch 24/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3537 - accuracy: 0.9093 - val_loss: 0.4147 - val_accuracy: 0.9077 - lr: 9.0000e-04\n",
            "Epoch 25/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3523 - accuracy: 0.9097 - val_loss: 0.4105 - val_accuracy: 0.9069 - lr: 9.0000e-04\n",
            "Epoch 26/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3455 - accuracy: 0.9129 - val_loss: 0.4107 - val_accuracy: 0.9091 - lr: 8.1000e-04\n",
            "Epoch 27/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3399 - accuracy: 0.9160 - val_loss: 0.4048 - val_accuracy: 0.9088 - lr: 8.1000e-04\n",
            "Epoch 28/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3410 - accuracy: 0.9159 - val_loss: 0.3982 - val_accuracy: 0.9119 - lr: 8.1000e-04\n",
            "Epoch 29/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3395 - accuracy: 0.9152 - val_loss: 0.4003 - val_accuracy: 0.9111 - lr: 8.1000e-04\n",
            "Epoch 30/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3427 - accuracy: 0.9149 - val_loss: 0.3980 - val_accuracy: 0.9114 - lr: 8.1000e-04\n",
            "Epoch 31/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3391 - accuracy: 0.9153 - val_loss: 0.3956 - val_accuracy: 0.9116 - lr: 8.1000e-04\n",
            "Epoch 32/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3374 - accuracy: 0.9145 - val_loss: 0.3957 - val_accuracy: 0.9136 - lr: 8.1000e-04\n",
            "Epoch 33/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3360 - accuracy: 0.9185 - val_loss: 0.3955 - val_accuracy: 0.9139 - lr: 8.1000e-04\n",
            "Epoch 34/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3401 - accuracy: 0.9149 - val_loss: 0.3986 - val_accuracy: 0.9129 - lr: 8.1000e-04\n",
            "Epoch 35/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3328 - accuracy: 0.9174 - val_loss: 0.3948 - val_accuracy: 0.9157 - lr: 8.1000e-04\n",
            "Epoch 36/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3359 - accuracy: 0.9184 - val_loss: 0.4005 - val_accuracy: 0.9149 - lr: 8.1000e-04\n",
            "Epoch 37/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3346 - accuracy: 0.9186 - val_loss: 0.3958 - val_accuracy: 0.9137 - lr: 8.1000e-04\n",
            "Epoch 38/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3355 - accuracy: 0.9182 - val_loss: 0.3938 - val_accuracy: 0.9162 - lr: 8.1000e-04\n",
            "Epoch 39/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3314 - accuracy: 0.9185 - val_loss: 0.4020 - val_accuracy: 0.9107 - lr: 8.1000e-04\n",
            "Epoch 40/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3303 - accuracy: 0.9198 - val_loss: 0.4057 - val_accuracy: 0.9082 - lr: 8.1000e-04\n",
            "Epoch 41/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3319 - accuracy: 0.9191 - val_loss: 0.3953 - val_accuracy: 0.9151 - lr: 8.1000e-04\n",
            "Epoch 42/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3276 - accuracy: 0.9220 - val_loss: 0.3935 - val_accuracy: 0.9158 - lr: 7.2900e-04\n",
            "Epoch 43/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3263 - accuracy: 0.9219 - val_loss: 0.3899 - val_accuracy: 0.9171 - lr: 7.2900e-04\n",
            "Epoch 44/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3248 - accuracy: 0.9222 - val_loss: 0.3928 - val_accuracy: 0.9144 - lr: 7.2900e-04\n",
            "Epoch 45/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3232 - accuracy: 0.9239 - val_loss: 0.3961 - val_accuracy: 0.9157 - lr: 7.2900e-04\n",
            "Epoch 46/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3248 - accuracy: 0.9233 - val_loss: 0.3888 - val_accuracy: 0.9166 - lr: 7.2900e-04\n",
            "Epoch 47/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3226 - accuracy: 0.9237 - val_loss: 0.3943 - val_accuracy: 0.9167 - lr: 7.2900e-04\n",
            "Epoch 48/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3246 - accuracy: 0.9236 - val_loss: 0.3903 - val_accuracy: 0.9163 - lr: 7.2900e-04\n",
            "Epoch 49/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3206 - accuracy: 0.9241 - val_loss: 0.3982 - val_accuracy: 0.9161 - lr: 7.2900e-04\n",
            "Epoch 50/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3195 - accuracy: 0.9256 - val_loss: 0.3924 - val_accuracy: 0.9170 - lr: 6.5610e-04\n",
            "Epoch 51/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3180 - accuracy: 0.9254 - val_loss: 0.3910 - val_accuracy: 0.9184 - lr: 6.5610e-04\n",
            "Epoch 52/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3180 - accuracy: 0.9252 - val_loss: 0.3904 - val_accuracy: 0.9168 - lr: 6.5610e-04\n",
            "Epoch 53/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3139 - accuracy: 0.9265 - val_loss: 0.3890 - val_accuracy: 0.9174 - lr: 5.9049e-04\n",
            "Epoch 54/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3163 - accuracy: 0.9250 - val_loss: 0.3912 - val_accuracy: 0.9167 - lr: 5.9049e-04\n",
            "Epoch 55/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3152 - accuracy: 0.9272 - val_loss: 0.3858 - val_accuracy: 0.9173 - lr: 5.9049e-04\n",
            "Epoch 56/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3141 - accuracy: 0.9275 - val_loss: 0.3877 - val_accuracy: 0.9188 - lr: 5.9049e-04\n",
            "Epoch 57/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3139 - accuracy: 0.9274 - val_loss: 0.3859 - val_accuracy: 0.9188 - lr: 5.9049e-04\n",
            "Epoch 58/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3106 - accuracy: 0.9285 - val_loss: 0.3875 - val_accuracy: 0.9164 - lr: 5.9049e-04\n",
            "Epoch 59/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3098 - accuracy: 0.9313 - val_loss: 0.3920 - val_accuracy: 0.9182 - lr: 5.3144e-04\n",
            "Epoch 60/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3083 - accuracy: 0.9295 - val_loss: 0.3885 - val_accuracy: 0.9189 - lr: 5.3144e-04\n",
            "Epoch 61/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3062 - accuracy: 0.9327 - val_loss: 0.3894 - val_accuracy: 0.9156 - lr: 5.3144e-04\n",
            "Epoch 62/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3051 - accuracy: 0.9320 - val_loss: 0.3883 - val_accuracy: 0.9191 - lr: 4.7830e-04\n",
            "Epoch 63/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3015 - accuracy: 0.9335 - val_loss: 0.3857 - val_accuracy: 0.9209 - lr: 4.7830e-04\n",
            "Epoch 64/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3023 - accuracy: 0.9327 - val_loss: 0.3860 - val_accuracy: 0.9165 - lr: 4.7830e-04\n",
            "Epoch 65/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.3020 - accuracy: 0.9331 - val_loss: 0.3875 - val_accuracy: 0.9201 - lr: 4.7830e-04\n",
            "Epoch 66/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3004 - accuracy: 0.9329 - val_loss: 0.3820 - val_accuracy: 0.9196 - lr: 4.7830e-04\n",
            "Epoch 67/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3010 - accuracy: 0.9333 - val_loss: 0.3901 - val_accuracy: 0.9155 - lr: 4.7830e-04\n",
            "Epoch 68/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2991 - accuracy: 0.9351 - val_loss: 0.3918 - val_accuracy: 0.9172 - lr: 4.7830e-04\n",
            "Epoch 69/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.3002 - accuracy: 0.9335 - val_loss: 0.3857 - val_accuracy: 0.9192 - lr: 4.7830e-04\n",
            "Epoch 70/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2981 - accuracy: 0.9335 - val_loss: 0.3854 - val_accuracy: 0.9188 - lr: 4.3047e-04\n",
            "Epoch 71/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2967 - accuracy: 0.9363 - val_loss: 0.3805 - val_accuracy: 0.9256 - lr: 4.3047e-04\n",
            "Epoch 72/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2938 - accuracy: 0.9364 - val_loss: 0.3851 - val_accuracy: 0.9182 - lr: 4.3047e-04\n",
            "Epoch 73/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2973 - accuracy: 0.9347 - val_loss: 0.3819 - val_accuracy: 0.9199 - lr: 4.3047e-04\n",
            "Epoch 74/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2953 - accuracy: 0.9349 - val_loss: 0.3812 - val_accuracy: 0.9188 - lr: 4.3047e-04\n",
            "Epoch 75/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2929 - accuracy: 0.9377 - val_loss: 0.3794 - val_accuracy: 0.9208 - lr: 3.8742e-04\n",
            "Epoch 76/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2916 - accuracy: 0.9386 - val_loss: 0.3802 - val_accuracy: 0.9212 - lr: 3.8742e-04\n",
            "Epoch 77/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2913 - accuracy: 0.9379 - val_loss: 0.3842 - val_accuracy: 0.9192 - lr: 3.8742e-04\n",
            "Epoch 78/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2907 - accuracy: 0.9391 - val_loss: 0.3850 - val_accuracy: 0.9208 - lr: 3.8742e-04\n",
            "Epoch 79/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2895 - accuracy: 0.9392 - val_loss: 0.3817 - val_accuracy: 0.9195 - lr: 3.4868e-04\n",
            "Epoch 80/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2893 - accuracy: 0.9392 - val_loss: 0.3790 - val_accuracy: 0.9233 - lr: 3.4868e-04\n",
            "Epoch 81/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2883 - accuracy: 0.9385 - val_loss: 0.3772 - val_accuracy: 0.9219 - lr: 3.4868e-04\n",
            "Epoch 82/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2863 - accuracy: 0.9404 - val_loss: 0.3789 - val_accuracy: 0.9228 - lr: 3.4868e-04\n",
            "Epoch 83/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2858 - accuracy: 0.9393 - val_loss: 0.3812 - val_accuracy: 0.9203 - lr: 3.4868e-04\n",
            "Epoch 84/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2862 - accuracy: 0.9415 - val_loss: 0.3820 - val_accuracy: 0.9206 - lr: 3.4868e-04\n",
            "Epoch 85/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2858 - accuracy: 0.9394 - val_loss: 0.3832 - val_accuracy: 0.9213 - lr: 3.1381e-04\n",
            "Epoch 86/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2853 - accuracy: 0.9421 - val_loss: 0.3784 - val_accuracy: 0.9202 - lr: 3.1381e-04\n",
            "Epoch 87/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2861 - accuracy: 0.9412 - val_loss: 0.3815 - val_accuracy: 0.9209 - lr: 3.1381e-04\n",
            "Epoch 88/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2825 - accuracy: 0.9436 - val_loss: 0.3803 - val_accuracy: 0.9222 - lr: 2.8243e-04\n",
            "Epoch 89/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2818 - accuracy: 0.9431 - val_loss: 0.3796 - val_accuracy: 0.9226 - lr: 2.8243e-04\n",
            "Epoch 90/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2813 - accuracy: 0.9430 - val_loss: 0.3806 - val_accuracy: 0.9227 - lr: 2.8243e-04\n",
            "Epoch 91/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2805 - accuracy: 0.9430 - val_loss: 0.3759 - val_accuracy: 0.9234 - lr: 2.5419e-04\n",
            "Epoch 92/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2787 - accuracy: 0.9440 - val_loss: 0.3788 - val_accuracy: 0.9227 - lr: 2.5419e-04\n",
            "Epoch 93/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2781 - accuracy: 0.9443 - val_loss: 0.3758 - val_accuracy: 0.9244 - lr: 2.5419e-04\n",
            "Epoch 94/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2788 - accuracy: 0.9458 - val_loss: 0.3818 - val_accuracy: 0.9207 - lr: 2.5419e-04\n",
            "Epoch 95/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2790 - accuracy: 0.9448 - val_loss: 0.3820 - val_accuracy: 0.9216 - lr: 2.5419e-04\n",
            "Epoch 96/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2777 - accuracy: 0.9461 - val_loss: 0.3779 - val_accuracy: 0.9218 - lr: 2.5419e-04\n",
            "Epoch 97/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2779 - accuracy: 0.9443 - val_loss: 0.3788 - val_accuracy: 0.9233 - lr: 2.2877e-04\n",
            "Epoch 98/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2770 - accuracy: 0.9444 - val_loss: 0.3805 - val_accuracy: 0.9223 - lr: 2.2877e-04\n",
            "Epoch 99/2000\n",
            "657/657 [==============================] - 7s 10ms/step - loss: 0.2763 - accuracy: 0.9441 - val_loss: 0.3804 - val_accuracy: 0.9230 - lr: 2.2877e-04\n",
            "Epoch 100/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2756 - accuracy: 0.9453 - val_loss: 0.3756 - val_accuracy: 0.9251 - lr: 2.0589e-04\n",
            "Epoch 101/2000\n",
            "657/657 [==============================] - 7s 11ms/step - loss: 0.2741 - accuracy: 0.9468 - val_loss: 0.3753 - val_accuracy: 0.9209 - lr: 2.0589e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0efe2a0b90>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-ishoDEnrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hImsZIESEnrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50ae378-cd3d-4a3a-f889-c67710983706"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8944"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no2.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "VWZax3eXMwej"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BUrklzVkE66r"
      ],
      "name": "uncertainty 기반 labeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}