{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YianKim/2020_EDAProject/blob/main/uncertainty_%EA%B8%B0%EB%B0%98_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQpjWg4Ld6m"
      },
      "source": [
        "## 구글 드라이브\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTEuhg7fR9P",
        "outputId": "d951b417-b43b-4fd8-bfb1-08fe2d7f9c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7KUb6NBs-"
      },
      "source": [
        "## 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "XRPQRtXGmm2W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import PIL\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LSTM\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import *\n",
        "from keras.models import load_model\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAjYytuPDaU"
      },
      "source": [
        "## 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "e6b1qO5dSAyP"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(data, labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "B-e24WMOTQ4d"
      },
      "outputs": [],
      "source": [
        "train_data = data[range(10000)].reshape([10000,28,28,1])\n",
        "train_labels = labels[range(10000)].reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "EhhKskDITIEm"
      },
      "outputs": [],
      "source": [
        "unlab_data = data[range(10000,60000)].reshape([50000,28,28,1])\n",
        "unlab_labels = labels[range(10000,60000)].reshape([50000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "W5aNLvjxVUq0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape([10000,28,28,1])\n",
        "test_labels = test_labels.reshape([10000,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2K2wXxMmUxRV"
      },
      "outputs": [],
      "source": [
        "train_labels2 = []\n",
        "unlab_labels2 = []\n",
        "test_labels2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "8c9LL8JVThd-"
      },
      "outputs": [],
      "source": [
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[train_labels[i][0]] = 1\n",
        "  train_labels2.append(white)\n",
        "\n",
        "for i in range(50000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[unlab_labels[i][0]] = 1\n",
        "  unlab_labels2.append(white)\n",
        "\n",
        "for i in range(10000):\n",
        "  white = [0,0,0,0,0,0,0,0,0,0]\n",
        "  white[test_labels[i][0]] = 1\n",
        "  test_labels2.append(white)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "iULFrchUU5nt"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_labels2)\n",
        "unlab_labels = np.array(unlab_labels2)\n",
        "test_labels = np.array(test_labels2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa7KYMfrkKU5"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "zn3v_W8wJQ68"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5scE9yKkIZb"
      },
      "outputs": [],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVOc3hYIkXrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5D8i_BCkdjS"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8ppILhFUrz"
      },
      "source": [
        "## 모델 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7Ljx2EWA2v2n"
      },
      "outputs": [],
      "source": [
        "def model_eval():\n",
        "  pred_mu = model.predict(test_data)\n",
        "  for i in range(1, 30):\n",
        "    pred_mu += model.predict(test_data)\n",
        "  pred_mu = pred_mu/30\n",
        "  predicted_test_labels = np.argmax(pred_mu, axis=1)\n",
        "  return(accuracy_score(np.argmax(test_labels, axis=1), predicted_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzhQw9NOWjl3",
        "outputId": "fda67dbf-826f-4cac-8cc8-f596eb647c13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcbs04885lTu"
      },
      "source": [
        "# 라벨링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtfoQKLZDJC"
      },
      "source": [
        "## 라벨링; 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GKJgmFGWhlfl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Jb5VX9ZC3y",
        "outputId": "d0f93ef2-55cb-4f92-a2e1-bd14d541b72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [02:20<00:00,  4.68s/it]\n",
            "100%|██████████| 50000/50000 [00:09<00:00, 5059.61it/s]\n"
          ]
        }
      ],
      "source": [
        "# Vars : 분산들\n",
        "# Outs : 결과 값들\n",
        "\n",
        "Vars = []\n",
        "Outs = []\n",
        "\n",
        "temp1 = []\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  temp1.append(model.predict(unlab_data))\n",
        "\n",
        "for j in tqdm(range(unlab_data.shape[0])):\n",
        "\n",
        "  temp2 = np.array([0,0,0,0,0,0,0,0,0,0], 'float32')\n",
        "  \n",
        "  for i in range(30):\n",
        "    temp2 += temp1[i][j]\n",
        "  Outs.append(temp2/30)\n",
        "  \n",
        "  outputs=[]\n",
        "\n",
        "  for i in range(30):\n",
        "    outputs.append(temp1[i][j][np.argmax(temp2)])\n",
        "  Vars.append(np.var(outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-NnAVIXTXlAa"
      },
      "outputs": [],
      "source": [
        "Outs = np.array(Outs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxIFHtGqAF9B"
      },
      "source": [
        "class마다 균등하게 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGGKCzvAiZb",
        "outputId": "97201ab5-f6ac-43e2-ae57-2f9c61326e94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 5058,\n",
              "         1: 4973,\n",
              "         2: 4984,\n",
              "         3: 4981,\n",
              "         4: 5026,\n",
              "         5: 5011,\n",
              "         6: 4979,\n",
              "         7: 4978,\n",
              "         8: 5010,\n",
              "         9: 5000})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불확정성 컷 1"
      ],
      "metadata": {
        "id": "BUrklzVkE66r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAwvSCVBLA4",
        "outputId": "2fc40e80-4c31-46d8-a5ab-273d54f3d629"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [01:24<00:00, 590.23it/s]\n",
            "100%|██████████| 50000/50000 [01:29<00:00, 561.58it/s]\n",
            "100%|██████████| 50000/50000 [01:25<00:00, 585.09it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 589.09it/s]\n",
            "100%|██████████| 50000/50000 [01:25<00:00, 585.43it/s]\n",
            "100%|██████████| 50000/50000 [01:26<00:00, 578.97it/s]\n",
            "100%|██████████| 50000/50000 [01:26<00:00, 578.81it/s]\n",
            "100%|██████████| 50000/50000 [01:27<00:00, 573.93it/s]\n",
            "100%|██████████| 50000/50000 [01:27<00:00, 573.30it/s]\n",
            "100%|██████████| 50000/50000 [01:24<00:00, 589.32it/s]\n"
          ]
        }
      ],
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB = []\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB.append(np.percentile(classvars, 50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BUHoKvtkJ37"
      },
      "outputs": [],
      "source": [
        "lowvars = []\n",
        "ind = 0 \n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    lowvars.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WhEDezq362P"
      },
      "outputs": [],
      "source": [
        "highvars = []\n",
        "for i in range(unlab_data.shape[0]):\n",
        "  if i not in lowvars:\n",
        "    highvars.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uSdhE1VmF5a",
        "outputId": "c427ea32-0e5c-4928-be41-4cdef55df959"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.89192"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtEPD5p5kM-z",
        "outputId": "e6c93b65-dfe5-49f6-ab77-79f7d0814c6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9728878433874247"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 저분산의 data들만 모아서 모델로 label 부여 후 정확도 측정 : 95% 이상\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2ab4GUWwe30"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xahhoBY8mKc"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gQWZXNojDvb"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tdOxYBQjFGT"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t9J8vlJ5TDO"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[randomindx2]\n",
        "unlab_labels_2 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Jq-n0L8diD",
        "outputId": "9dfcefff-d842-4581-de6b-579daea38e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 3600,\n",
              "         1: 3599,\n",
              "         2: 3613,\n",
              "         3: 3638,\n",
              "         4: 3469,\n",
              "         5: 3491,\n",
              "         6: 3151,\n",
              "         7: 3507,\n",
              "         8: 3505,\n",
              "         9: 3508})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CLpAKvu8kD6",
        "outputId": "00fce93a-128c-471e-d460-410106f853da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 3409,\n",
              "         1: 3473,\n",
              "         2: 3582,\n",
              "         3: 3546,\n",
              "         4: 3512,\n",
              "         5: 3488,\n",
              "         6: 3448,\n",
              "         7: 3581,\n",
              "         8: 3447,\n",
              "         9: 3514})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5t5J130x7pe",
        "outputId": "6c32f60a-2251-4d7c-e35a-b8e445dbb790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 2529,\n",
              "         1: 2407,\n",
              "         2: 2492,\n",
              "         3: 2490,\n",
              "         4: 2513,\n",
              "         5: 2505,\n",
              "         6: 2489,\n",
              "         7: 2489,\n",
              "         8: 2505,\n",
              "         9: 2500})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBMxw6eEx92l",
        "outputId": "57ac6607-fa7f-4bc9-8e0b-f4e876ab52d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 2565,\n",
              "         1: 2496,\n",
              "         2: 2452,\n",
              "         3: 2497,\n",
              "         4: 2506,\n",
              "         5: 2458,\n",
              "         6: 2504,\n",
              "         7: 2474,\n",
              "         8: 2554,\n",
              "         9: 2494})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불확정성 컷 2"
      ],
      "metadata": {
        "id": "qXY6ufSkE_rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upper bound of variance?\n",
        "\n",
        "UB25 = []\n",
        "UB50 = []\n",
        "UB75 = []\n",
        "\n",
        "\n",
        "for h in range(10):\n",
        "  classvars = []\n",
        "  for i in tqdm(range(50000)):\n",
        "    if np.argmax(unlab_labels, axis=1).tolist()[i]==h:\n",
        "      classvars.append(Vars[i])\n",
        "  UB25.append(np.percentile(classvars, 25))\n",
        "  UB50.append(np.percentile(classvars, 50))\n",
        "  UB75.append(np.percentile(classvars, 75))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEPgF4EWEdGx",
        "outputId": "a8cf1391-3f7d-4cba-8dc3-da3d550fb14c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [01:30<00:00, 551.98it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 549.83it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.37it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.61it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.75it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.93it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.57it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.84it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 550.87it/s]\n",
            "100%|██████████| 50000/50000 [01:30<00:00, 554.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UB25 < UB50 < UB75"
      ],
      "metadata": {
        "id": "F2m-BBSNFRO6"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "xOq_mV-uFGKX"
      },
      "outputs": [],
      "source": [
        "vars25 = []\n",
        "vars50 = []\n",
        "vars75 = []\n",
        "vars100 = []\n",
        "\n",
        "ind = 0 \n",
        "\n",
        "\n",
        "for i in Vars:\n",
        "  if i <= UB25[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars25.append(ind)\n",
        "  elif i <= UB50[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars50.append(ind)\n",
        "  elif i <= UB75[np.argmax(unlab_labels, axis=1)[ind]]:\n",
        "    vars75.append(ind)\n",
        "  else:\n",
        "    vars100.append(ind)\n",
        "  ind += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k1 = random.sample(range(len(vars25)), len(vars25))\n",
        "k2 = random.sample(range(len(vars50)), len(vars50))\n",
        "k3 = random.sample(range(len(vars75)), len(vars75))\n",
        "k4 = random.sample(range(len(vars100)), len(vars100))\n",
        "\n",
        "lowvars = k1[0:np.int(len(k1)/2)] + k2[0:np.int(len(k2)/2)] + k3[0:np.int(len(k3)/2)] + k4[0:np.int(len(k4)/2)]\n",
        "highvars = k1[np.int(len(k1)/2):len(k1)] + k2[np.int(len(k2)/2):len(k2)] + k3[np.int(len(k3)/2):len(k3)] + k4[np.int(len(k4)/2):len(k4)]"
      ],
      "metadata": {
        "id": "5kx2MFUxKh6d"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd92645b-33e9-4c72-b97e-2f6621304739",
        "id": "cHARP-fyFGKX"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89368"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# 같은 길이의 랜덤하게 고른 data들에 모델로 label 부여 후 정확도 측정\n",
        "randomindx = random.sample(range(50000), 50000)\n",
        "randomindx2 = randomindx[0:25000]\n",
        "randomindx = randomindx[25000:50000]\n",
        "accuracy_score(np.argmax(np.array(Outs)[randomindx], axis=1), np.argmax(unlab_labels[randomindx], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740fa621-a072-4c6d-d81e-8dbc43513c32",
        "id": "DU2TXlLaFGKY"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8886355454218169"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# 층화추출\n",
        "accuracy_score(np.argmax(np.array(Outs)[lowvars], axis=1), np.argmax(unlab_labels[lowvars], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1ka9xFulFGKY"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data, unlab_data[lowvars]], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels, Outs[lowvars]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "uLqnYj4ZFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_1.shape[0]),train_data_1.shape[0])\n",
        "train_data_1 = train_data_1[shufindx]\n",
        "train_labels_1 = train_labels_1[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "nvb7FhRaFGKZ"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data, unlab_data[randomindx]], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels, Outs[randomindx]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "PsSWcAFHFGKZ"
      },
      "outputs": [],
      "source": [
        "shufindx = random.sample(range(train_data_2.shape[0]),train_data_2.shape[0])\n",
        "train_data_2 = train_data_2[shufindx]\n",
        "train_labels_2 = train_labels_2[shufindx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "F39Oc7V8FGKZ"
      },
      "outputs": [],
      "source": [
        "unlab_data_1 = unlab_data[highvars]\n",
        "unlab_labels_1 = unlab_labels[highvars]\n",
        "unlab_data_2 = unlab_data[randomindx2]\n",
        "unlab_labels_2 = unlab_labels[randomindx2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9f0065-2cd2-4914-caf8-b9e01c797d33",
        "id": "MMw4VfmaFGKZ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3508,\n",
              "         1: 3486,\n",
              "         2: 3582,\n",
              "         3: 3547,\n",
              "         4: 3447,\n",
              "         5: 3504,\n",
              "         6: 3439,\n",
              "         7: 3561,\n",
              "         8: 3389,\n",
              "         9: 3536})"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89f7d03-fe6b-43e7-e5a7-5fba60f30a54",
        "id": "o5ZZKXxBFGKZ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3429,\n",
              "         1: 3481,\n",
              "         2: 3664,\n",
              "         3: 3562,\n",
              "         4: 3454,\n",
              "         5: 3453,\n",
              "         6: 3428,\n",
              "         7: 3563,\n",
              "         8: 3505,\n",
              "         9: 3461})"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "Counter(np.argmax(train_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655b9ddf-33b7-4ec3-8314-661ab323e10e",
        "id": "Y05Wb3HZFGKa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2471,\n",
              "         1: 2497,\n",
              "         2: 2417,\n",
              "         3: 2519,\n",
              "         4: 2512,\n",
              "         5: 2544,\n",
              "         6: 2636,\n",
              "         7: 2460,\n",
              "         8: 2434,\n",
              "         9: 2511})"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_1, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3391d66-96fd-494b-d0a2-bfa849b39d13",
        "id": "qHWvlgD4FGKa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2544,\n",
              "         1: 2480,\n",
              "         2: 2405,\n",
              "         3: 2509,\n",
              "         4: 2543,\n",
              "         5: 2511,\n",
              "         6: 2495,\n",
              "         7: 2481,\n",
              "         8: 2493,\n",
              "         9: 2539})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "Counter(np.argmax(unlab_labels_2, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOtFA9fr5oDF"
      },
      "source": [
        "## 모델링\n",
        "\n",
        "간단한 모델에서 받은 지식를 복잡한 모델에서 학습 \n",
        "\n",
        "uncertainty aware data vs random sampling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "m7Pd9SYK5tv_"
      },
      "outputs": [],
      "source": [
        "def PermaDropout(rate):\n",
        "    return Lambda(lambda x: K.dropout(x, level=rate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6WgyM3Y5twA",
        "outputId": "fce245f5-c053-4b30-a02c-eed4b12cda4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 1.3518 - accuracy: 0.5796 - val_loss: 0.7088 - val_accuracy: 0.7650 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.6536 - accuracy: 0.7771 - val_loss: 0.5978 - val_accuracy: 0.7984 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.5668 - accuracy: 0.8099 - val_loss: 0.5404 - val_accuracy: 0.8269 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.5271 - accuracy: 0.8246 - val_loss: 0.5126 - val_accuracy: 0.8374 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4989 - accuracy: 0.8376 - val_loss: 0.4965 - val_accuracy: 0.8393 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4687 - accuracy: 0.8521 - val_loss: 0.4725 - val_accuracy: 0.8545 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4447 - accuracy: 0.8593 - val_loss: 0.4490 - val_accuracy: 0.8633 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4232 - accuracy: 0.8702 - val_loss: 0.4286 - val_accuracy: 0.8673 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4172 - accuracy: 0.8744 - val_loss: 0.4106 - val_accuracy: 0.8806 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3970 - accuracy: 0.8828 - val_loss: 0.4194 - val_accuracy: 0.8775 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4021 - accuracy: 0.8818 - val_loss: 0.4025 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3841 - accuracy: 0.8862 - val_loss: 0.3931 - val_accuracy: 0.8871 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3773 - accuracy: 0.8908 - val_loss: 0.3931 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3776 - accuracy: 0.8922 - val_loss: 0.3852 - val_accuracy: 0.8907 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3726 - accuracy: 0.8933 - val_loss: 0.3855 - val_accuracy: 0.8869 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3693 - accuracy: 0.8949 - val_loss: 0.3879 - val_accuracy: 0.8893 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3644 - accuracy: 0.8971 - val_loss: 0.3797 - val_accuracy: 0.8911 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3567 - accuracy: 0.9022 - val_loss: 0.3792 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3550 - accuracy: 0.9019 - val_loss: 0.3789 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3552 - accuracy: 0.8999 - val_loss: 0.3767 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3462 - accuracy: 0.9070 - val_loss: 0.3720 - val_accuracy: 0.8990 - lr: 0.0010\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3491 - accuracy: 0.9039 - val_loss: 0.3791 - val_accuracy: 0.8921 - lr: 0.0010\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3451 - accuracy: 0.9075 - val_loss: 0.3767 - val_accuracy: 0.8946 - lr: 0.0010\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3386 - accuracy: 0.9091 - val_loss: 0.3665 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3383 - accuracy: 0.9099 - val_loss: 0.3867 - val_accuracy: 0.8930 - lr: 0.0010\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3366 - accuracy: 0.9100 - val_loss: 0.3776 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3348 - accuracy: 0.9112 - val_loss: 0.3595 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3325 - accuracy: 0.9124 - val_loss: 0.3624 - val_accuracy: 0.9004 - lr: 0.0010\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3343 - accuracy: 0.9099 - val_loss: 0.3568 - val_accuracy: 0.9001 - lr: 0.0010\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3313 - accuracy: 0.9108 - val_loss: 0.3601 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3206 - accuracy: 0.9176 - val_loss: 0.3544 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3202 - accuracy: 0.9175 - val_loss: 0.3617 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3228 - accuracy: 0.9170 - val_loss: 0.3595 - val_accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3263 - accuracy: 0.9163 - val_loss: 0.3588 - val_accuracy: 0.8993 - lr: 0.0010\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3157 - accuracy: 0.9192 - val_loss: 0.3597 - val_accuracy: 0.9014 - lr: 9.0000e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3131 - accuracy: 0.9198 - val_loss: 0.3513 - val_accuracy: 0.9070 - lr: 9.0000e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3131 - accuracy: 0.9215 - val_loss: 0.3558 - val_accuracy: 0.9050 - lr: 9.0000e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3100 - accuracy: 0.9242 - val_loss: 0.3498 - val_accuracy: 0.9065 - lr: 9.0000e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3065 - accuracy: 0.9251 - val_loss: 0.3518 - val_accuracy: 0.9037 - lr: 9.0000e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3065 - accuracy: 0.9246 - val_loss: 0.3483 - val_accuracy: 0.9085 - lr: 9.0000e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3057 - accuracy: 0.9241 - val_loss: 0.3586 - val_accuracy: 0.9026 - lr: 9.0000e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3066 - accuracy: 0.9250 - val_loss: 0.3561 - val_accuracy: 0.9007 - lr: 9.0000e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3042 - accuracy: 0.9235 - val_loss: 0.3464 - val_accuracy: 0.9071 - lr: 9.0000e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3050 - accuracy: 0.9267 - val_loss: 0.3521 - val_accuracy: 0.9043 - lr: 9.0000e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3034 - accuracy: 0.9264 - val_loss: 0.3490 - val_accuracy: 0.9052 - lr: 9.0000e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3031 - accuracy: 0.9252 - val_loss: 0.3506 - val_accuracy: 0.9030 - lr: 9.0000e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2972 - accuracy: 0.9289 - val_loss: 0.3566 - val_accuracy: 0.9059 - lr: 8.1000e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2933 - accuracy: 0.9329 - val_loss: 0.3456 - val_accuracy: 0.9104 - lr: 8.1000e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2939 - accuracy: 0.9320 - val_loss: 0.3432 - val_accuracy: 0.9095 - lr: 8.1000e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2924 - accuracy: 0.9307 - val_loss: 0.3473 - val_accuracy: 0.9122 - lr: 8.1000e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2916 - accuracy: 0.9311 - val_loss: 0.3486 - val_accuracy: 0.9058 - lr: 8.1000e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2920 - accuracy: 0.9319 - val_loss: 0.3388 - val_accuracy: 0.9133 - lr: 8.1000e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2879 - accuracy: 0.9333 - val_loss: 0.3486 - val_accuracy: 0.9058 - lr: 8.1000e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2900 - accuracy: 0.9322 - val_loss: 0.3398 - val_accuracy: 0.9081 - lr: 8.1000e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2872 - accuracy: 0.9346 - val_loss: 0.3488 - val_accuracy: 0.9092 - lr: 8.1000e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2819 - accuracy: 0.9364 - val_loss: 0.3414 - val_accuracy: 0.9112 - lr: 7.2900e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2846 - accuracy: 0.9378 - val_loss: 0.3494 - val_accuracy: 0.9080 - lr: 7.2900e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2826 - accuracy: 0.9378 - val_loss: 0.3345 - val_accuracy: 0.9131 - lr: 7.2900e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2811 - accuracy: 0.9362 - val_loss: 0.3383 - val_accuracy: 0.9089 - lr: 7.2900e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2776 - accuracy: 0.9378 - val_loss: 0.3350 - val_accuracy: 0.9108 - lr: 7.2900e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2771 - accuracy: 0.9402 - val_loss: 0.3387 - val_accuracy: 0.9098 - lr: 7.2900e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2764 - accuracy: 0.9374 - val_loss: 0.3403 - val_accuracy: 0.9109 - lr: 6.5610e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2720 - accuracy: 0.9420 - val_loss: 0.3317 - val_accuracy: 0.9146 - lr: 6.5610e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2735 - accuracy: 0.9397 - val_loss: 0.3374 - val_accuracy: 0.9150 - lr: 6.5610e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2721 - accuracy: 0.9415 - val_loss: 0.3310 - val_accuracy: 0.9174 - lr: 6.5610e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2718 - accuracy: 0.9399 - val_loss: 0.3307 - val_accuracy: 0.9155 - lr: 6.5610e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2717 - accuracy: 0.9441 - val_loss: 0.3361 - val_accuracy: 0.9120 - lr: 6.5610e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2684 - accuracy: 0.9427 - val_loss: 0.3403 - val_accuracy: 0.9140 - lr: 6.5610e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2700 - accuracy: 0.9418 - val_loss: 0.3352 - val_accuracy: 0.9127 - lr: 6.5610e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2672 - accuracy: 0.9441 - val_loss: 0.3332 - val_accuracy: 0.9152 - lr: 5.9049e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2652 - accuracy: 0.9460 - val_loss: 0.3259 - val_accuracy: 0.9136 - lr: 5.9049e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2633 - accuracy: 0.9453 - val_loss: 0.3260 - val_accuracy: 0.9190 - lr: 5.9049e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2654 - accuracy: 0.9465 - val_loss: 0.3319 - val_accuracy: 0.9141 - lr: 5.9049e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2599 - accuracy: 0.9480 - val_loss: 0.3297 - val_accuracy: 0.9163 - lr: 5.9049e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2593 - accuracy: 0.9481 - val_loss: 0.3268 - val_accuracy: 0.9200 - lr: 5.3144e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2608 - accuracy: 0.9455 - val_loss: 0.3306 - val_accuracy: 0.9187 - lr: 5.3144e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2573 - accuracy: 0.9481 - val_loss: 0.3261 - val_accuracy: 0.9155 - lr: 5.3144e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2556 - accuracy: 0.9509 - val_loss: 0.3306 - val_accuracy: 0.9171 - lr: 4.7830e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2540 - accuracy: 0.9516 - val_loss: 0.3244 - val_accuracy: 0.9177 - lr: 4.7830e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2537 - accuracy: 0.9508 - val_loss: 0.3257 - val_accuracy: 0.9190 - lr: 4.7830e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2528 - accuracy: 0.9502 - val_loss: 0.3237 - val_accuracy: 0.9173 - lr: 4.7830e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2515 - accuracy: 0.9495 - val_loss: 0.3292 - val_accuracy: 0.9194 - lr: 4.7830e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2506 - accuracy: 0.9512 - val_loss: 0.3284 - val_accuracy: 0.9147 - lr: 4.7830e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2516 - accuracy: 0.9528 - val_loss: 0.3267 - val_accuracy: 0.9147 - lr: 4.7830e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2490 - accuracy: 0.9523 - val_loss: 0.3202 - val_accuracy: 0.9226 - lr: 4.3047e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2475 - accuracy: 0.9533 - val_loss: 0.3247 - val_accuracy: 0.9215 - lr: 4.3047e-04\n",
            "Epoch 87/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2483 - accuracy: 0.9545 - val_loss: 0.3255 - val_accuracy: 0.9224 - lr: 4.3047e-04\n",
            "Epoch 88/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2476 - accuracy: 0.9537 - val_loss: 0.3219 - val_accuracy: 0.9206 - lr: 4.3047e-04\n",
            "Epoch 89/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2442 - accuracy: 0.9539 - val_loss: 0.3241 - val_accuracy: 0.9194 - lr: 3.8742e-04\n",
            "Epoch 90/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2443 - accuracy: 0.9563 - val_loss: 0.3257 - val_accuracy: 0.9208 - lr: 3.8742e-04\n",
            "Epoch 91/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2444 - accuracy: 0.9558 - val_loss: 0.3223 - val_accuracy: 0.9214 - lr: 3.8742e-04\n",
            "Epoch 92/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2425 - accuracy: 0.9564 - val_loss: 0.3168 - val_accuracy: 0.9248 - lr: 3.4868e-04\n",
            "Epoch 93/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2408 - accuracy: 0.9581 - val_loss: 0.3208 - val_accuracy: 0.9202 - lr: 3.4868e-04\n",
            "Epoch 94/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2411 - accuracy: 0.9571 - val_loss: 0.3243 - val_accuracy: 0.9210 - lr: 3.4868e-04\n",
            "Epoch 95/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2402 - accuracy: 0.9568 - val_loss: 0.3191 - val_accuracy: 0.9261 - lr: 3.4868e-04\n",
            "Epoch 96/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2397 - accuracy: 0.9584 - val_loss: 0.3229 - val_accuracy: 0.9220 - lr: 3.1381e-04\n",
            "Epoch 97/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2390 - accuracy: 0.9576 - val_loss: 0.3166 - val_accuracy: 0.9247 - lr: 3.1381e-04\n",
            "Epoch 98/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2376 - accuracy: 0.9582 - val_loss: 0.3227 - val_accuracy: 0.9239 - lr: 3.1381e-04\n",
            "Epoch 99/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2390 - accuracy: 0.9574 - val_loss: 0.3248 - val_accuracy: 0.9215 - lr: 3.1381e-04\n",
            "Epoch 100/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2363 - accuracy: 0.9591 - val_loss: 0.3150 - val_accuracy: 0.9202 - lr: 3.1381e-04\n",
            "Epoch 101/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2374 - accuracy: 0.9600 - val_loss: 0.3200 - val_accuracy: 0.9223 - lr: 3.1381e-04\n",
            "Epoch 102/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2356 - accuracy: 0.9613 - val_loss: 0.3191 - val_accuracy: 0.9221 - lr: 3.1381e-04\n",
            "Epoch 103/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2359 - accuracy: 0.9588 - val_loss: 0.3160 - val_accuracy: 0.9219 - lr: 3.1381e-04\n",
            "Epoch 104/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2366 - accuracy: 0.9585 - val_loss: 0.3212 - val_accuracy: 0.9238 - lr: 2.8243e-04\n",
            "Epoch 105/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2335 - accuracy: 0.9605 - val_loss: 0.3220 - val_accuracy: 0.9239 - lr: 2.8243e-04\n",
            "Epoch 106/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2347 - accuracy: 0.9597 - val_loss: 0.3133 - val_accuracy: 0.9265 - lr: 2.8243e-04\n",
            "Epoch 107/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2332 - accuracy: 0.9607 - val_loss: 0.3146 - val_accuracy: 0.9230 - lr: 2.8243e-04\n",
            "Epoch 108/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2343 - accuracy: 0.9606 - val_loss: 0.3162 - val_accuracy: 0.9257 - lr: 2.8243e-04\n",
            "Epoch 109/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2342 - accuracy: 0.9602 - val_loss: 0.3176 - val_accuracy: 0.9209 - lr: 2.8243e-04\n",
            "Epoch 110/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2326 - accuracy: 0.9606 - val_loss: 0.3237 - val_accuracy: 0.9232 - lr: 2.5419e-04\n",
            "Epoch 111/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2315 - accuracy: 0.9614 - val_loss: 0.3184 - val_accuracy: 0.9220 - lr: 2.5419e-04\n",
            "Epoch 112/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2317 - accuracy: 0.9617 - val_loss: 0.3144 - val_accuracy: 0.9240 - lr: 2.5419e-04\n",
            "Epoch 113/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2297 - accuracy: 0.9620 - val_loss: 0.3151 - val_accuracy: 0.9252 - lr: 2.2877e-04\n",
            "Epoch 114/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2303 - accuracy: 0.9608 - val_loss: 0.3154 - val_accuracy: 0.9251 - lr: 2.2877e-04\n",
            "Epoch 115/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2301 - accuracy: 0.9629 - val_loss: 0.3163 - val_accuracy: 0.9226 - lr: 2.2877e-04\n",
            "Epoch 116/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2289 - accuracy: 0.9621 - val_loss: 0.3160 - val_accuracy: 0.9219 - lr: 2.0589e-04\n",
            "Epoch 117/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2283 - accuracy: 0.9624 - val_loss: 0.3195 - val_accuracy: 0.9244 - lr: 2.0589e-04\n",
            "Epoch 118/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2271 - accuracy: 0.9628 - val_loss: 0.3151 - val_accuracy: 0.9236 - lr: 2.0589e-04\n",
            "Epoch 119/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2280 - accuracy: 0.9633 - val_loss: 0.3135 - val_accuracy: 0.9261 - lr: 1.8530e-04\n",
            "Epoch 120/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2270 - accuracy: 0.9644 - val_loss: 0.3117 - val_accuracy: 0.9259 - lr: 1.8530e-04\n",
            "Epoch 121/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2266 - accuracy: 0.9649 - val_loss: 0.3151 - val_accuracy: 0.9238 - lr: 1.8530e-04\n",
            "Epoch 122/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2259 - accuracy: 0.9632 - val_loss: 0.3128 - val_accuracy: 0.9242 - lr: 1.8530e-04\n",
            "Epoch 123/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2266 - accuracy: 0.9646 - val_loss: 0.3168 - val_accuracy: 0.9281 - lr: 1.8530e-04\n",
            "Epoch 124/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2255 - accuracy: 0.9647 - val_loss: 0.3176 - val_accuracy: 0.9250 - lr: 1.6677e-04\n",
            "Epoch 125/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2256 - accuracy: 0.9643 - val_loss: 0.3140 - val_accuracy: 0.9260 - lr: 1.6677e-04\n",
            "Epoch 126/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2261 - accuracy: 0.9640 - val_loss: 0.3157 - val_accuracy: 0.9224 - lr: 1.6677e-04\n",
            "Epoch 127/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2240 - accuracy: 0.9664 - val_loss: 0.3166 - val_accuracy: 0.9259 - lr: 1.5009e-04\n",
            "Epoch 128/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2259 - accuracy: 0.9648 - val_loss: 0.3152 - val_accuracy: 0.9238 - lr: 1.5009e-04\n",
            "Epoch 129/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2242 - accuracy: 0.9642 - val_loss: 0.3175 - val_accuracy: 0.9251 - lr: 1.5009e-04\n",
            "Epoch 130/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2240 - accuracy: 0.9647 - val_loss: 0.3097 - val_accuracy: 0.9289 - lr: 1.3509e-04\n",
            "Epoch 131/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2240 - accuracy: 0.9660 - val_loss: 0.3147 - val_accuracy: 0.9239 - lr: 1.3509e-04\n",
            "Epoch 132/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2227 - accuracy: 0.9662 - val_loss: 0.3121 - val_accuracy: 0.9279 - lr: 1.3509e-04\n",
            "Epoch 133/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2231 - accuracy: 0.9669 - val_loss: 0.3113 - val_accuracy: 0.9271 - lr: 1.3509e-04\n",
            "Epoch 134/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2223 - accuracy: 0.9660 - val_loss: 0.3094 - val_accuracy: 0.9263 - lr: 1.2158e-04\n",
            "Epoch 135/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2228 - accuracy: 0.9654 - val_loss: 0.3104 - val_accuracy: 0.9273 - lr: 1.2158e-04\n",
            "Epoch 136/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2215 - accuracy: 0.9658 - val_loss: 0.3051 - val_accuracy: 0.9267 - lr: 1.2158e-04\n",
            "Epoch 137/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2218 - accuracy: 0.9662 - val_loss: 0.3138 - val_accuracy: 0.9246 - lr: 1.2158e-04\n",
            "Epoch 138/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2215 - accuracy: 0.9658 - val_loss: 0.3154 - val_accuracy: 0.9290 - lr: 1.2158e-04\n",
            "Epoch 139/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2217 - accuracy: 0.9669 - val_loss: 0.3135 - val_accuracy: 0.9233 - lr: 1.2158e-04\n",
            "Epoch 140/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2214 - accuracy: 0.9675 - val_loss: 0.3132 - val_accuracy: 0.9276 - lr: 1.0942e-04\n",
            "Epoch 141/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2213 - accuracy: 0.9665 - val_loss: 0.3062 - val_accuracy: 0.9303 - lr: 1.0942e-04\n",
            "Epoch 142/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2210 - accuracy: 0.9673 - val_loss: 0.3176 - val_accuracy: 0.9248 - lr: 1.0942e-04\n",
            "Epoch 143/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2209 - accuracy: 0.9658 - val_loss: 0.3125 - val_accuracy: 0.9270 - lr: 9.8477e-05\n",
            "Epoch 144/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2208 - accuracy: 0.9660 - val_loss: 0.3146 - val_accuracy: 0.9272 - lr: 9.8477e-05\n",
            "Epoch 145/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2200 - accuracy: 0.9666 - val_loss: 0.3127 - val_accuracy: 0.9285 - lr: 9.8477e-05\n",
            "Epoch 146/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2202 - accuracy: 0.9679 - val_loss: 0.3149 - val_accuracy: 0.9247 - lr: 8.8629e-05\n",
            "Epoch 147/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2197 - accuracy: 0.9680 - val_loss: 0.3151 - val_accuracy: 0.9290 - lr: 8.8629e-05\n",
            "Epoch 148/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2193 - accuracy: 0.9673 - val_loss: 0.3100 - val_accuracy: 0.9261 - lr: 8.8629e-05\n",
            "Epoch 149/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2192 - accuracy: 0.9667 - val_loss: 0.3119 - val_accuracy: 0.9273 - lr: 7.9766e-05\n",
            "Epoch 150/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2194 - accuracy: 0.9675 - val_loss: 0.3110 - val_accuracy: 0.9290 - lr: 7.9766e-05\n",
            "Epoch 151/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2191 - accuracy: 0.9677 - val_loss: 0.3094 - val_accuracy: 0.9255 - lr: 7.9766e-05\n",
            "Epoch 152/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2192 - accuracy: 0.9679 - val_loss: 0.3139 - val_accuracy: 0.9249 - lr: 7.1790e-05\n",
            "Epoch 153/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2188 - accuracy: 0.9662 - val_loss: 0.3103 - val_accuracy: 0.9249 - lr: 7.1790e-05\n",
            "Epoch 154/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2178 - accuracy: 0.9681 - val_loss: 0.3121 - val_accuracy: 0.9284 - lr: 7.1790e-05\n",
            "Epoch 155/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2186 - accuracy: 0.9664 - val_loss: 0.3103 - val_accuracy: 0.9291 - lr: 6.4611e-05\n",
            "Epoch 156/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2175 - accuracy: 0.9695 - val_loss: 0.3079 - val_accuracy: 0.9282 - lr: 6.4611e-05\n",
            "Epoch 157/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2203 - accuracy: 0.9667 - val_loss: 0.3130 - val_accuracy: 0.9249 - lr: 6.4611e-05\n",
            "Epoch 158/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2175 - accuracy: 0.9702 - val_loss: 0.3117 - val_accuracy: 0.9276 - lr: 5.8150e-05\n",
            "Epoch 159/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2169 - accuracy: 0.9685 - val_loss: 0.3090 - val_accuracy: 0.9295 - lr: 5.8150e-05\n",
            "Epoch 160/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2180 - accuracy: 0.9667 - val_loss: 0.3107 - val_accuracy: 0.9267 - lr: 5.8150e-05\n",
            "Epoch 161/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2174 - accuracy: 0.9686 - val_loss: 0.3119 - val_accuracy: 0.9265 - lr: 5.2335e-05\n",
            "Epoch 162/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2171 - accuracy: 0.9690 - val_loss: 0.3105 - val_accuracy: 0.9271 - lr: 5.2335e-05\n",
            "Epoch 163/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2168 - accuracy: 0.9682 - val_loss: 0.3060 - val_accuracy: 0.9301 - lr: 5.2335e-05\n",
            "Epoch 164/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2178 - accuracy: 0.9668 - val_loss: 0.3115 - val_accuracy: 0.9265 - lr: 4.7101e-05\n",
            "Epoch 165/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2175 - accuracy: 0.9687 - val_loss: 0.3080 - val_accuracy: 0.9264 - lr: 4.7101e-05\n",
            "Epoch 166/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2177 - accuracy: 0.9675 - val_loss: 0.3080 - val_accuracy: 0.9278 - lr: 4.7101e-05\n",
            "Epoch 167/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2161 - accuracy: 0.9676 - val_loss: 0.3123 - val_accuracy: 0.9286 - lr: 4.2391e-05\n",
            "Epoch 168/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2163 - accuracy: 0.9702 - val_loss: 0.3118 - val_accuracy: 0.9271 - lr: 4.2391e-05\n",
            "Epoch 169/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2163 - accuracy: 0.9688 - val_loss: 0.3141 - val_accuracy: 0.9248 - lr: 4.2391e-05\n",
            "Epoch 170/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2168 - accuracy: 0.9691 - val_loss: 0.3079 - val_accuracy: 0.9254 - lr: 3.8152e-05\n",
            "Epoch 171/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2168 - accuracy: 0.9691 - val_loss: 0.3141 - val_accuracy: 0.9262 - lr: 3.8152e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27475a5190>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "9_zB1OL252B3"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbEZKkhn52B4",
        "outputId": "d4f79ab1-11b1-4d2c-9171-4b3723afc14f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.891"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KTK643Nkt4E",
        "outputId": "bd190dfa-c240-465a-ff11-3f8942db6f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 1.1803 - accuracy: 0.6096 - val_loss: 0.6667 - val_accuracy: 0.7740 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.6082 - accuracy: 0.7905 - val_loss: 0.5672 - val_accuracy: 0.8093 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "383/383 [==============================] - 8s 21ms/step - loss: 0.5290 - accuracy: 0.8217 - val_loss: 0.5196 - val_accuracy: 0.8318 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4852 - accuracy: 0.8405 - val_loss: 0.4826 - val_accuracy: 0.8488 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4569 - accuracy: 0.8543 - val_loss: 0.4636 - val_accuracy: 0.8581 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.4396 - accuracy: 0.8632 - val_loss: 0.4338 - val_accuracy: 0.8680 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.4252 - accuracy: 0.8669 - val_loss: 0.4308 - val_accuracy: 0.8759 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.4062 - accuracy: 0.8797 - val_loss: 0.4201 - val_accuracy: 0.8755 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3977 - accuracy: 0.8819 - val_loss: 0.4057 - val_accuracy: 0.8796 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3931 - accuracy: 0.8836 - val_loss: 0.3968 - val_accuracy: 0.8830 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3753 - accuracy: 0.8916 - val_loss: 0.3999 - val_accuracy: 0.8873 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3741 - accuracy: 0.8914 - val_loss: 0.3952 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3657 - accuracy: 0.8963 - val_loss: 0.4036 - val_accuracy: 0.8810 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3667 - accuracy: 0.8940 - val_loss: 0.3876 - val_accuracy: 0.8899 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3637 - accuracy: 0.8978 - val_loss: 0.3838 - val_accuracy: 0.8914 - lr: 0.0010\n",
            "Epoch 16/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3541 - accuracy: 0.8984 - val_loss: 0.3988 - val_accuracy: 0.8854 - lr: 0.0010\n",
            "Epoch 17/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3513 - accuracy: 0.9000 - val_loss: 0.3990 - val_accuracy: 0.8838 - lr: 0.0010\n",
            "Epoch 18/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3503 - accuracy: 0.9045 - val_loss: 0.3919 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Epoch 19/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3416 - accuracy: 0.9080 - val_loss: 0.3804 - val_accuracy: 0.8948 - lr: 9.0000e-04\n",
            "Epoch 20/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3371 - accuracy: 0.9084 - val_loss: 0.3699 - val_accuracy: 0.8965 - lr: 9.0000e-04\n",
            "Epoch 21/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3323 - accuracy: 0.9094 - val_loss: 0.3808 - val_accuracy: 0.8970 - lr: 9.0000e-04\n",
            "Epoch 22/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3373 - accuracy: 0.9085 - val_loss: 0.3717 - val_accuracy: 0.8997 - lr: 9.0000e-04\n",
            "Epoch 23/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3343 - accuracy: 0.9107 - val_loss: 0.3740 - val_accuracy: 0.8968 - lr: 9.0000e-04\n",
            "Epoch 24/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3259 - accuracy: 0.9153 - val_loss: 0.3687 - val_accuracy: 0.8936 - lr: 8.1000e-04\n",
            "Epoch 25/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3232 - accuracy: 0.9136 - val_loss: 0.3658 - val_accuracy: 0.9008 - lr: 8.1000e-04\n",
            "Epoch 26/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3200 - accuracy: 0.9139 - val_loss: 0.3666 - val_accuracy: 0.9009 - lr: 8.1000e-04\n",
            "Epoch 27/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3167 - accuracy: 0.9175 - val_loss: 0.3661 - val_accuracy: 0.8990 - lr: 8.1000e-04\n",
            "Epoch 28/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3131 - accuracy: 0.9180 - val_loss: 0.3596 - val_accuracy: 0.8992 - lr: 8.1000e-04\n",
            "Epoch 29/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3132 - accuracy: 0.9195 - val_loss: 0.3749 - val_accuracy: 0.8979 - lr: 8.1000e-04\n",
            "Epoch 30/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3152 - accuracy: 0.9189 - val_loss: 0.3697 - val_accuracy: 0.8979 - lr: 8.1000e-04\n",
            "Epoch 31/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3092 - accuracy: 0.9211 - val_loss: 0.3644 - val_accuracy: 0.9036 - lr: 8.1000e-04\n",
            "Epoch 32/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3079 - accuracy: 0.9213 - val_loss: 0.3648 - val_accuracy: 0.9024 - lr: 7.2900e-04\n",
            "Epoch 33/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.3039 - accuracy: 0.9242 - val_loss: 0.3604 - val_accuracy: 0.9063 - lr: 7.2900e-04\n",
            "Epoch 34/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.3027 - accuracy: 0.9242 - val_loss: 0.3661 - val_accuracy: 0.9015 - lr: 7.2900e-04\n",
            "Epoch 35/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2998 - accuracy: 0.9265 - val_loss: 0.3591 - val_accuracy: 0.9040 - lr: 6.5610e-04\n",
            "Epoch 36/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2965 - accuracy: 0.9273 - val_loss: 0.3638 - val_accuracy: 0.8970 - lr: 6.5610e-04\n",
            "Epoch 37/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2941 - accuracy: 0.9264 - val_loss: 0.3542 - val_accuracy: 0.9061 - lr: 6.5610e-04\n",
            "Epoch 38/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2930 - accuracy: 0.9264 - val_loss: 0.3655 - val_accuracy: 0.9038 - lr: 6.5610e-04\n",
            "Epoch 39/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2923 - accuracy: 0.9287 - val_loss: 0.3572 - val_accuracy: 0.9041 - lr: 6.5610e-04\n",
            "Epoch 40/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2911 - accuracy: 0.9288 - val_loss: 0.3640 - val_accuracy: 0.9062 - lr: 6.5610e-04\n",
            "Epoch 41/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2879 - accuracy: 0.9297 - val_loss: 0.3628 - val_accuracy: 0.9040 - lr: 5.9049e-04\n",
            "Epoch 42/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2861 - accuracy: 0.9303 - val_loss: 0.3579 - val_accuracy: 0.9070 - lr: 5.9049e-04\n",
            "Epoch 43/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2836 - accuracy: 0.9300 - val_loss: 0.3571 - val_accuracy: 0.9063 - lr: 5.9049e-04\n",
            "Epoch 44/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2812 - accuracy: 0.9345 - val_loss: 0.3575 - val_accuracy: 0.9055 - lr: 5.3144e-04\n",
            "Epoch 45/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2780 - accuracy: 0.9349 - val_loss: 0.3543 - val_accuracy: 0.9071 - lr: 5.3144e-04\n",
            "Epoch 46/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2782 - accuracy: 0.9367 - val_loss: 0.3576 - val_accuracy: 0.9048 - lr: 5.3144e-04\n",
            "Epoch 47/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2757 - accuracy: 0.9371 - val_loss: 0.3523 - val_accuracy: 0.9054 - lr: 4.7830e-04\n",
            "Epoch 48/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2725 - accuracy: 0.9363 - val_loss: 0.3545 - val_accuracy: 0.9036 - lr: 4.7830e-04\n",
            "Epoch 49/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2724 - accuracy: 0.9373 - val_loss: 0.3534 - val_accuracy: 0.9034 - lr: 4.7830e-04\n",
            "Epoch 50/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2704 - accuracy: 0.9396 - val_loss: 0.3561 - val_accuracy: 0.9052 - lr: 4.7830e-04\n",
            "Epoch 51/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2693 - accuracy: 0.9400 - val_loss: 0.3561 - val_accuracy: 0.9070 - lr: 4.3047e-04\n",
            "Epoch 52/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2670 - accuracy: 0.9409 - val_loss: 0.3550 - val_accuracy: 0.9084 - lr: 4.3047e-04\n",
            "Epoch 53/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2648 - accuracy: 0.9419 - val_loss: 0.3531 - val_accuracy: 0.9110 - lr: 4.3047e-04\n",
            "Epoch 54/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2655 - accuracy: 0.9433 - val_loss: 0.3499 - val_accuracy: 0.9083 - lr: 3.8742e-04\n",
            "Epoch 55/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2609 - accuracy: 0.9446 - val_loss: 0.3480 - val_accuracy: 0.9093 - lr: 3.8742e-04\n",
            "Epoch 56/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2622 - accuracy: 0.9441 - val_loss: 0.3457 - val_accuracy: 0.9067 - lr: 3.8742e-04\n",
            "Epoch 57/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2634 - accuracy: 0.9447 - val_loss: 0.3518 - val_accuracy: 0.9070 - lr: 3.8742e-04\n",
            "Epoch 58/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2599 - accuracy: 0.9453 - val_loss: 0.3497 - val_accuracy: 0.9076 - lr: 3.8742e-04\n",
            "Epoch 59/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2593 - accuracy: 0.9447 - val_loss: 0.3515 - val_accuracy: 0.9089 - lr: 3.8742e-04\n",
            "Epoch 60/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2578 - accuracy: 0.9453 - val_loss: 0.3544 - val_accuracy: 0.9067 - lr: 3.4868e-04\n",
            "Epoch 61/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2570 - accuracy: 0.9462 - val_loss: 0.3442 - val_accuracy: 0.9090 - lr: 3.4868e-04\n",
            "Epoch 62/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2538 - accuracy: 0.9485 - val_loss: 0.3537 - val_accuracy: 0.9093 - lr: 3.4868e-04\n",
            "Epoch 63/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2546 - accuracy: 0.9466 - val_loss: 0.3519 - val_accuracy: 0.9097 - lr: 3.4868e-04\n",
            "Epoch 64/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2528 - accuracy: 0.9491 - val_loss: 0.3473 - val_accuracy: 0.9062 - lr: 3.4868e-04\n",
            "Epoch 65/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2521 - accuracy: 0.9478 - val_loss: 0.3464 - val_accuracy: 0.9081 - lr: 3.1381e-04\n",
            "Epoch 66/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2509 - accuracy: 0.9487 - val_loss: 0.3517 - val_accuracy: 0.9076 - lr: 3.1381e-04\n",
            "Epoch 67/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2503 - accuracy: 0.9509 - val_loss: 0.3471 - val_accuracy: 0.9087 - lr: 3.1381e-04\n",
            "Epoch 68/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2501 - accuracy: 0.9497 - val_loss: 0.3503 - val_accuracy: 0.9113 - lr: 2.8243e-04\n",
            "Epoch 69/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2481 - accuracy: 0.9493 - val_loss: 0.3453 - val_accuracy: 0.9116 - lr: 2.8243e-04\n",
            "Epoch 70/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2475 - accuracy: 0.9510 - val_loss: 0.3480 - val_accuracy: 0.9058 - lr: 2.8243e-04\n",
            "Epoch 71/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2477 - accuracy: 0.9500 - val_loss: 0.3494 - val_accuracy: 0.9086 - lr: 2.5419e-04\n",
            "Epoch 72/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2445 - accuracy: 0.9533 - val_loss: 0.3500 - val_accuracy: 0.9042 - lr: 2.5419e-04\n",
            "Epoch 73/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2464 - accuracy: 0.9524 - val_loss: 0.3448 - val_accuracy: 0.9096 - lr: 2.5419e-04\n",
            "Epoch 74/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2442 - accuracy: 0.9532 - val_loss: 0.3550 - val_accuracy: 0.9111 - lr: 2.2877e-04\n",
            "Epoch 75/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2431 - accuracy: 0.9533 - val_loss: 0.3514 - val_accuracy: 0.9089 - lr: 2.2877e-04\n",
            "Epoch 76/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2428 - accuracy: 0.9516 - val_loss: 0.3510 - val_accuracy: 0.9102 - lr: 2.2877e-04\n",
            "Epoch 77/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2434 - accuracy: 0.9533 - val_loss: 0.3447 - val_accuracy: 0.9123 - lr: 2.0589e-04\n",
            "Epoch 78/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2416 - accuracy: 0.9531 - val_loss: 0.3488 - val_accuracy: 0.9114 - lr: 2.0589e-04\n",
            "Epoch 79/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2402 - accuracy: 0.9557 - val_loss: 0.3493 - val_accuracy: 0.9106 - lr: 2.0589e-04\n",
            "Epoch 80/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2392 - accuracy: 0.9558 - val_loss: 0.3519 - val_accuracy: 0.9091 - lr: 1.8530e-04\n",
            "Epoch 81/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2381 - accuracy: 0.9554 - val_loss: 0.3429 - val_accuracy: 0.9129 - lr: 1.8530e-04\n",
            "Epoch 82/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2359 - accuracy: 0.9562 - val_loss: 0.3462 - val_accuracy: 0.9117 - lr: 1.8530e-04\n",
            "Epoch 83/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2379 - accuracy: 0.9539 - val_loss: 0.3504 - val_accuracy: 0.9106 - lr: 1.8530e-04\n",
            "Epoch 84/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2378 - accuracy: 0.9558 - val_loss: 0.3437 - val_accuracy: 0.9109 - lr: 1.8530e-04\n",
            "Epoch 85/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2372 - accuracy: 0.9573 - val_loss: 0.3452 - val_accuracy: 0.9117 - lr: 1.6677e-04\n",
            "Epoch 86/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2357 - accuracy: 0.9566 - val_loss: 0.3464 - val_accuracy: 0.9124 - lr: 1.6677e-04\n",
            "Epoch 87/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2351 - accuracy: 0.9569 - val_loss: 0.3468 - val_accuracy: 0.9095 - lr: 1.6677e-04\n",
            "Epoch 88/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2351 - accuracy: 0.9556 - val_loss: 0.3423 - val_accuracy: 0.9101 - lr: 1.5009e-04\n",
            "Epoch 89/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2332 - accuracy: 0.9580 - val_loss: 0.3464 - val_accuracy: 0.9107 - lr: 1.5009e-04\n",
            "Epoch 90/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2345 - accuracy: 0.9578 - val_loss: 0.3459 - val_accuracy: 0.9170 - lr: 1.5009e-04\n",
            "Epoch 91/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2333 - accuracy: 0.9578 - val_loss: 0.3485 - val_accuracy: 0.9114 - lr: 1.5009e-04\n",
            "Epoch 92/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2327 - accuracy: 0.9573 - val_loss: 0.3455 - val_accuracy: 0.9103 - lr: 1.3509e-04\n",
            "Epoch 93/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2327 - accuracy: 0.9598 - val_loss: 0.3426 - val_accuracy: 0.9120 - lr: 1.3509e-04\n",
            "Epoch 94/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2326 - accuracy: 0.9596 - val_loss: 0.3390 - val_accuracy: 0.9128 - lr: 1.3509e-04\n",
            "Epoch 95/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2322 - accuracy: 0.9579 - val_loss: 0.3497 - val_accuracy: 0.9113 - lr: 1.3509e-04\n",
            "Epoch 96/2000\n",
            "383/383 [==============================] - 9s 22ms/step - loss: 0.2319 - accuracy: 0.9593 - val_loss: 0.3464 - val_accuracy: 0.9101 - lr: 1.3509e-04\n",
            "Epoch 97/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2334 - accuracy: 0.9588 - val_loss: 0.3447 - val_accuracy: 0.9110 - lr: 1.3509e-04\n",
            "Epoch 98/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2303 - accuracy: 0.9593 - val_loss: 0.3437 - val_accuracy: 0.9130 - lr: 1.2158e-04\n",
            "Epoch 99/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2302 - accuracy: 0.9612 - val_loss: 0.3487 - val_accuracy: 0.9089 - lr: 1.2158e-04\n",
            "Epoch 100/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2302 - accuracy: 0.9596 - val_loss: 0.3480 - val_accuracy: 0.9107 - lr: 1.2158e-04\n",
            "Epoch 101/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2288 - accuracy: 0.9608 - val_loss: 0.3454 - val_accuracy: 0.9080 - lr: 1.0942e-04\n",
            "Epoch 102/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2284 - accuracy: 0.9597 - val_loss: 0.3485 - val_accuracy: 0.9094 - lr: 1.0942e-04\n",
            "Epoch 103/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2283 - accuracy: 0.9628 - val_loss: 0.3444 - val_accuracy: 0.9131 - lr: 1.0942e-04\n",
            "Epoch 104/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2296 - accuracy: 0.9586 - val_loss: 0.3458 - val_accuracy: 0.9122 - lr: 9.8477e-05\n",
            "Epoch 105/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2275 - accuracy: 0.9600 - val_loss: 0.3479 - val_accuracy: 0.9085 - lr: 9.8477e-05\n",
            "Epoch 106/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2279 - accuracy: 0.9603 - val_loss: 0.3496 - val_accuracy: 0.9106 - lr: 9.8477e-05\n",
            "Epoch 107/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2275 - accuracy: 0.9639 - val_loss: 0.3487 - val_accuracy: 0.9108 - lr: 8.8629e-05\n",
            "Epoch 108/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2265 - accuracy: 0.9609 - val_loss: 0.3464 - val_accuracy: 0.9105 - lr: 8.8629e-05\n",
            "Epoch 109/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2271 - accuracy: 0.9605 - val_loss: 0.3430 - val_accuracy: 0.9126 - lr: 8.8629e-05\n",
            "Epoch 110/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2261 - accuracy: 0.9629 - val_loss: 0.3468 - val_accuracy: 0.9113 - lr: 7.9766e-05\n",
            "Epoch 111/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2267 - accuracy: 0.9622 - val_loss: 0.3447 - val_accuracy: 0.9122 - lr: 7.9766e-05\n",
            "Epoch 112/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2267 - accuracy: 0.9607 - val_loss: 0.3476 - val_accuracy: 0.9095 - lr: 7.9766e-05\n",
            "Epoch 113/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2266 - accuracy: 0.9619 - val_loss: 0.3456 - val_accuracy: 0.9155 - lr: 7.1790e-05\n",
            "Epoch 114/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2251 - accuracy: 0.9618 - val_loss: 0.3453 - val_accuracy: 0.9131 - lr: 7.1790e-05\n",
            "Epoch 115/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2240 - accuracy: 0.9621 - val_loss: 0.3457 - val_accuracy: 0.9135 - lr: 7.1790e-05\n",
            "Epoch 116/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2240 - accuracy: 0.9633 - val_loss: 0.3446 - val_accuracy: 0.9126 - lr: 6.4611e-05\n",
            "Epoch 117/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2241 - accuracy: 0.9638 - val_loss: 0.3443 - val_accuracy: 0.9111 - lr: 6.4611e-05\n",
            "Epoch 118/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2259 - accuracy: 0.9611 - val_loss: 0.3453 - val_accuracy: 0.9157 - lr: 6.4611e-05\n",
            "Epoch 119/2000\n",
            "383/383 [==============================] - 9s 23ms/step - loss: 0.2252 - accuracy: 0.9625 - val_loss: 0.3483 - val_accuracy: 0.9105 - lr: 5.8150e-05\n",
            "Epoch 120/2000\n",
            "383/383 [==============================] - 8s 22ms/step - loss: 0.2242 - accuracy: 0.9625 - val_loss: 0.3484 - val_accuracy: 0.9127 - lr: 5.8150e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2748bc2550>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "4d3W-766kt4H"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it79cIfekt4H",
        "outputId": "5fa94efb-80aa-4e0c-938e-fc7a551dbbd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.893"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kdx4FDw7ED"
      },
      "source": [
        "# 남은 데이터 라벨링하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "s8F_ifi6w9Uq"
      },
      "outputs": [],
      "source": [
        "model1 = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn2.h5')\n",
        "model2 = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "74E6i_eCxCNG"
      },
      "outputs": [],
      "source": [
        "unlab_label_1 = model1.predict(unlab_data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "_tz_MEzhxXos"
      },
      "outputs": [],
      "source": [
        "unlab_label_2 = model2.predict(unlab_data_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "tiz6rZkT5ORw"
      },
      "outputs": [],
      "source": [
        "train_data_1 = np.concatenate([train_data_1, unlab_data_1], axis=0)\n",
        "train_labels_1 = np.concatenate([train_labels_1, unlab_label_1], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "vIe8iZLkD8pJ"
      },
      "outputs": [],
      "source": [
        "train_data_2 = np.concatenate([train_data_2, unlab_data_2], axis=0)\n",
        "train_labels_2 = np.concatenate([train_labels_2, unlab_label_2], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru605cBREQ_8",
        "outputId": "3497b41c-567b-4f09-d47c-6c37c7728d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "657/657 [==============================] - 17s 24ms/step - loss: 1.0846 - accuracy: 0.6199 - val_loss: 0.6432 - val_accuracy: 0.7925 - lr: 0.0010\n",
            "Epoch 2/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.5814 - accuracy: 0.8075 - val_loss: 0.5579 - val_accuracy: 0.8241 - lr: 0.0010\n",
            "Epoch 3/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.5200 - accuracy: 0.8325 - val_loss: 0.4998 - val_accuracy: 0.8548 - lr: 0.0010\n",
            "Epoch 4/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.4643 - accuracy: 0.8607 - val_loss: 0.4565 - val_accuracy: 0.8761 - lr: 0.0010\n",
            "Epoch 5/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.4392 - accuracy: 0.8724 - val_loss: 0.4518 - val_accuracy: 0.8794 - lr: 0.0010\n",
            "Epoch 6/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.4224 - accuracy: 0.8797 - val_loss: 0.4349 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Epoch 7/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.4036 - accuracy: 0.8887 - val_loss: 0.4290 - val_accuracy: 0.8919 - lr: 0.0010\n",
            "Epoch 8/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.3964 - accuracy: 0.8880 - val_loss: 0.4173 - val_accuracy: 0.9016 - lr: 0.0010\n",
            "Epoch 9/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.3922 - accuracy: 0.8927 - val_loss: 0.4149 - val_accuracy: 0.9004 - lr: 0.0010\n",
            "Epoch 10/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.3793 - accuracy: 0.8972 - val_loss: 0.4051 - val_accuracy: 0.9056 - lr: 0.0010\n",
            "Epoch 11/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.3768 - accuracy: 0.8991 - val_loss: 0.4177 - val_accuracy: 0.9001 - lr: 0.0010\n",
            "Epoch 12/2000\n",
            "657/657 [==============================] - 15s 22ms/step - loss: 0.3769 - accuracy: 0.8994 - val_loss: 0.4127 - val_accuracy: 0.9047 - lr: 0.0010\n",
            "Epoch 13/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.3675 - accuracy: 0.9019 - val_loss: 0.4038 - val_accuracy: 0.9084 - lr: 0.0010\n",
            "Epoch 14/2000\n",
            "657/657 [==============================] - 15s 23ms/step - loss: 0.3651 - accuracy: 0.9048 - val_loss: 0.4042 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Epoch 15/2000\n",
            "384/657 [================>.............] - ETA: 5s - loss: 0.3607 - accuracy: 0.9049"
          ]
        }
      ],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_1,\n",
        "          train_labels_1,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuG_m7tXEi2g"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDtQKCLqElcC"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn3.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJwnKwlXEVf7"
      },
      "outputs": [],
      "source": [
        "#######HYPERPARAMATERS###########\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "#################################\n",
        "  \n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28,28,1), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(PermaDropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "adam = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "          train_data_2,\n",
        "          train_labels_2,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.3,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, early_stopper]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-ishoDEnrl"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hImsZIESEnrl"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/파이썬스터디 프로젝트/labeling_cnn_no2.h5')\n",
        "model_eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VWZax3eXMwej"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "uncertainty 기반 labeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}